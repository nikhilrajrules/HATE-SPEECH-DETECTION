{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"attention_task1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3QxoDFxRvZ2K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"dc46728c-6bab-4d0c-8350-a3b017600af4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6stsQl9Qa_je","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"147611b5-fec9-4530-dc80-7e92dfcaa861"},"source":["%tensorflow_version 1.x #use tensorflow magic to use version 1.x in colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NdDIMLMhyoHr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2159dd7b-985e-4339-8a8f-c17765479e2d"},"source":["#imports\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import io\n","from nltk.corpus import stopwords\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem.porter import PorterStemmer\n","from keras.preprocessing import text as keras_text, sequence as keras_seq\n","from keras.utils import np_utils\n","from keras.layers import Conv1D, GlobalMaxPooling1D\n","from keras.layers import Dense, Activation, Convolution1D, MaxPooling1D, Dropout, Flatten\n","from keras.models import Sequential, save_model\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Embedding\n","from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2lTN2bzPzHO2","colab_type":"code","colab":{}},"source":["df_train=pd.read_csv(\"/content/drive/My Drive/minor/english_dataset/english_dataset_prepro.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CwQUqcNdNv1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"e3c41dce-c189-44e3-eb06-65619ddcc1ee"},"source":["df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","      <th>task_2</th>\n","      <th>task_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hasoc_en_1</td>\n","      <td>dhonikeepstheglove watch sports minister kiren...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>hasoc_en_2</td>\n","      <td>politico remember clearly individual1 admitted...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>hasoc_en_3</td>\n","      <td>cricketworldcup guess would winner cwc19 team ...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>hasoc_en_4</td>\n","      <td>corbyn politically intellectual borisjohnsonsh...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>hasoc_en_5</td>\n","      <td>best teamindia another swimming competition su...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      text_id                                               text  ... task_2 task_3\n","0  hasoc_en_1  dhonikeepstheglove watch sports minister kiren...  ...   NONE   NONE\n","1  hasoc_en_2  politico remember clearly individual1 admitted...  ...   HATE    TIN\n","2  hasoc_en_3  cricketworldcup guess would winner cwc19 team ...  ...   NONE   NONE\n","3  hasoc_en_4  corbyn politically intellectual borisjohnsonsh...  ...   NONE   NONE\n","4  hasoc_en_5  best teamindia another swimming competition su...  ...   NONE   NONE\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"SilkiBB6zJGA","colab_type":"code","colab":{}},"source":["Column_Sequence=np.array(df_train[\"text\"],dtype=\"str\") #storing value  of tweets or text in numpy array of strings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4Cv8RXLcNRA","colab_type":"code","colab":{}},"source":["Tokenizer=RegexpTokenizer(r\"\\w+[a-z]+\") #create a reg exp tokenizer object for text to make a list of strings and lowercase text (earlier also removed stopwords but that has been moved to preprocessing code)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCYO8WUSzK48","colab_type":"code","colab":{}},"source":["fresh=[]\n","for ix in Column_Sequence:\n","    sen=ix.lower()                        #lower case\n","    sen=Tokenizer.tokenize(sen)           #tokenize the sentences.\n","    wordss=[(Word) for Word in sen]\n","    sentance=\" \".join(wordss)\n","    fresh.append(sentance)                #append all in one."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQijZsYtzNAr","colab_type":"code","colab":{}},"source":["tokenizer = keras_text.Tokenizer(char_level = False,lower=True) #create a kerastokenizer object\n","t=tokenizer.fit_on_texts(list(fresh))                           #fit on training text\n","list_tokenized_train = tokenizer.texts_to_sequences(fresh)\n","X_t = keras_seq.pad_sequences(list_tokenized_train, maxlen=300,padding=\"post\") #maxlen after padding 300\n","word_index = tokenizer.word_index      #get a list of all tokens or words in the vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GsUTF2deTgZE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"64161abe-ddd6-4180-98c9-415e46114639"},"source":["#extract word2vec vectors for words in vocab\n","import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","#load word2vec vectors from file.\n","word_vectors = KeyedVectors.load_word2vec_format('/content/drive/My Drive/minor/wordtovec/GoogleNews-vectors-negative300.bin.gz', binary=True)\n","\n","EMBEDDING_DIM=300\n","vocabulary_size=len(word_index)+1\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector            #store the vector if found.\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)  #store a rndom vector if not found\n","\n","del(word_vectors)  #del word2vec vectors to free memory\n","\n","from keras.layers import Embedding\n","#create an embediing layer from word2vec vectors of our vocab\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xsmvQINM9aeI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"dcbf433c-2f06-4e8e-8d6d-11e2ea62499a"},"source":["len(tokenizer.word_counts)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16526"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"iFk50bF-9acF","colab_type":"code","colab":{}},"source":["X_train=X_t      #training text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uws-4mjU9qep","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f68e1e65-3302-4118-f77c-fa31bad89579"},"source":["X_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5852, 300)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"7XYjg7oe9sAV","colab_type":"code","colab":{}},"source":["Y=df_train[\"task_1\"]   #labels of classes with strings."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJpxBhBY9vgw","colab_type":"code","colab":{}},"source":["Y = Y.map({'HOF':0, 'NOT': 1})  #map the class names to numbers."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYN6U0ab90AG","colab_type":"code","colab":{}},"source":["# One-hot encode label\n","Y_train=np_utils.to_categorical(Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwkh_aL4912g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"966b7639-4811-4e34-87e2-d7a2dd55f86e"},"source":["Y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5852, 2)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"N-C4VvFF93V8","colab_type":"code","colab":{}},"source":["x_train, x_test, y_train, y_test = train_test_split(X_train,Y_train, test_size=0.10, random_state=42) #training validation split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHz7bwBp941M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"741ae9a5-81c6-4936-e53f-5849981c2457"},"source":["y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5266, 2)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"2iRdenDb96VP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ce6323fc-829e-4fb4-da5f-39026472f27d"},"source":["x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5266, 300)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"YOhfz_lK97zo","colab_type":"code","colab":{}},"source":["max_len=300   #length of text sequence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBZ7wggajCRi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"7a986ca2-659c-40ea-cb83-d06242c68098"},"source":["x_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    4,    21,   188, ...,     0,     0,     0],\n","       [ 1495,  1247,    70, ...,     0,     0,     0],\n","       [ 9400,  9401,  2422, ...,     0,     0,     0],\n","       ...,\n","       [ 3805,  2826, 15341, ...,     0,     0,     0],\n","       [  665, 15679,   968, ...,     0,     0,     0],\n","       [  382,  3152,  8291, ...,     0,     0,     0]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"c0RCXnxrwL4l","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, Input , Layer\n","from keras.layers import Embedding, GRU, Bidirectional , Reshape, Dot\n","from keras.models import Sequential, Model\n","from keras.layers.merge import concatenate\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import Input\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils.vis_utils import plot_model\n","from keras.models import Model\n","from keras import metrics\n","from keras import backend as K\n","from keras.regularizers import l2\n","import tensorflow as tf\n","from keras import initializers ,constraints, regularizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LTIy8oM9wEAk","colab_type":"code","colab":{}},"source":["#implementation of attention layer in keras\n","def dot_product(x, kernel):\n","    \"\"\"\n","    Wrapper for dot product operation, in order to be compatible with both\n","    Theano and Tensorflow\n","    Args:\n","        x (): input\n","        kernel (): weights\n","    Returns:\n","    \"\"\"\n","    if K.backend() == 'tensorflow':\n","        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n","    else:\n","        return K.dot(x, kernel)\n","    \n","\n","class AttentionWithContext(Layer):\n","    \"\"\"\n","    Attention operation, with a context/query vector, for temporal data.\n","    Supports Masking.\n","    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n","    \"Hierarchical Attention Networks for Document Classification\"\n","    by using a context vector to assist the attention\n","    # Input shape\n","        3D tensor with shape: `(samples, steps, features)`.\n","    # Output shape\n","        2D tensor with shape: `(samples, features)`.\n","    How to use:\n","    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n","    The dimensions are inferred based on the output shape of the RNN.\n","    Note: The layer has been tested with Keras 2.0.6\n","    Example:\n","        model.add(LSTM(64, return_sequences=True))\n","        model.add(AttentionWithContext())\n","        # next add a Dense layer (for classification/regression) or whatever...\n","    \"\"\"\n","\n","    def __init__(self,\n","                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        super(AttentionWithContext, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight(shape=(input_shape[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","\n","        self.u = self.add_weight(shape=(input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        super(AttentionWithContext, self).build(input_shape)\n","\n","    def compute_mask(self, input, input_mask=None):\n","        # do not pass the mask to the next layers\n","        return None\n","\n","    def call(self, x, mask=None):\n","        uit = dot_product(x, self.W)\n","\n","        if self.bias:\n","            uit += self.b\n","\n","        uit = K.tanh(uit)\n","        ait = dot_product(uit, self.u)\n","\n","        a = K.exp(ait)\n","\n","        # apply mask after the exp. will be re-normalized next\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= K.cast(mask, K.floatx())\n","\n","        # in some cases especially in the early stages of training the sum may be almost zero\n","        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n","        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0], input_shape[-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ju2L7fVjiOB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":479},"outputId":"cfdb072e-60ad-4702-9071-8f0f4fd4372c"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, CuDNNGRU\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#BiGRU+ATTENTION\n","sequence_input2 = Input(shape=(max_len,), dtype='int32') #input layer\n","embedded_sequences2 = embedding_layer(sequence_input2)\n","gru1=Bidirectional(CuDNNGRU(128, return_sequences=True))(embedded_sequences2) #bidirectional gru layer optimized for gpu\n","gru2= Bidirectional(CuDNNGRU(128, return_sequences=True))(gru1)\n","attn_outs=AttentionWithContext()(gru2) #attention layer\n","l_dense2 = Dense(128, activation='relu')(attn_outs)\n","preds2 = Dense(2, activation='softmax')(l_dense2) #ouput layer\n","\n","model2 = Model(sequence_input2, preds2)\n","model2.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","print(\"Bi-GRU+ATTENTION\")\n","model2.summary()\n","cp2=ModelCheckpoint('model_gru_attn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","GRU\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 300)               0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 300, 300)          4958100   \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 300, 256)          330240    \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 300, 256)          296448    \n","_________________________________________________________________\n","attention_with_context_1 (At (None, 256)               66048     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 5,683,990\n","Trainable params: 5,683,990\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_riePM31kx0M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"5b059684-57af-4152-be06-5db00b57872a"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D, Bidirectional\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, CuDNNLSTM\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#BI-LSTM+ATTENTION\n","sequence_input3 = Input(shape=(max_len,), dtype='int32') #input layer\n","embedded_sequences3 = embedding_layer(sequence_input3)\n","lstm1 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(embedded_sequences3) #bi-directional lstm layer optimized for gpu\n","lstm2= Bidirectional(CuDNNLSTM(128, return_sequences=True))(lstm1)\n","attn_outs3=AttentionWithContext()(lstm2) #attention layer\n","l_dense3 = Dense(128, activation='relu')(attn_outs3)\n","preds3 = Dense(2, activation='softmax')(l_dense3) #output layer\n","\n","model3 = Model(sequence_input3, preds3)\n","model3.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","print(\"Bi-LSTM+Attention\")\n","model3.summary()\n","cp3=ModelCheckpoint('model_lstm_attn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LSTM\n","Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 300)               0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 300, 300)          4958100   \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 300, 256)          440320    \n","_________________________________________________________________\n","bidirectional_4 (Bidirection (None, 300, 256)          395264    \n","_________________________________________________________________\n","attention_with_context_2 (At (None, 256)               66048     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 5,892,886\n","Trainable params: 5,892,886\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"svJu2O-Qm9gQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":564},"outputId":"bbb17097-7ccd-4d89-d3c1-e73c7217d63b"},"source":["history2=model2.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=7, batch_size=32,callbacks=[cp2]) #train bigru with attention with checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 5266 samples, validate on 586 samples\n","Epoch 1/7\n","5266/5266 [==============================] - 50s 9ms/step - loss: 0.6578 - acc: 0.6215 - val_loss: 0.6200 - val_acc: 0.6758\n","\n","Epoch 00001: val_acc improved from -inf to 0.67577, saving model to model_gru_attn.hdf5\n","Epoch 2/7\n","5266/5266 [==============================] - 44s 8ms/step - loss: 0.5830 - acc: 0.6943 - val_loss: 0.5745 - val_acc: 0.6928\n","\n","Epoch 00002: val_acc improved from 0.67577 to 0.69283, saving model to model_gru_attn.hdf5\n","Epoch 3/7\n","5266/5266 [==============================] - 43s 8ms/step - loss: 0.4487 - acc: 0.8035 - val_loss: 0.6471 - val_acc: 0.6860\n","\n","Epoch 00003: val_acc did not improve from 0.69283\n","Epoch 4/7\n","5266/5266 [==============================] - 43s 8ms/step - loss: 0.2696 - acc: 0.8919 - val_loss: 0.7606 - val_acc: 0.6468\n","\n","Epoch 00004: val_acc did not improve from 0.69283\n","Epoch 5/7\n","5266/5266 [==============================] - 41s 8ms/step - loss: 0.1515 - acc: 0.9432 - val_loss: 0.9597 - val_acc: 0.6672\n","\n","Epoch 00005: val_acc did not improve from 0.69283\n","Epoch 6/7\n","5266/5266 [==============================] - 41s 8ms/step - loss: 0.0968 - acc: 0.9654 - val_loss: 1.3170 - val_acc: 0.6519\n","\n","Epoch 00006: val_acc did not improve from 0.69283\n","Epoch 7/7\n","5266/5266 [==============================] - 41s 8ms/step - loss: 0.0630 - acc: 0.9757 - val_loss: 1.5440 - val_acc: 0.6485\n","\n","Epoch 00007: val_acc did not improve from 0.69283\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hl296E72nu9w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"outputId":"c3123042-aa48-41e1-baf1-ebfc8734ce1c"},"source":["history3=model3.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=7, batch_size=32,callbacks=[cp3]) #train bilstm with attention with checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 5266 samples, validate on 586 samples\n","Epoch 1/7\n","5266/5266 [==============================] - 41s 8ms/step - loss: 0.2449 - acc: 0.8965 - val_loss: 0.9824 - val_acc: 0.6604\n","\n","Epoch 00001: val_acc improved from -inf to 0.66041, saving model to model_lstm_attn.hdf5\n","Epoch 2/7\n","5266/5266 [==============================] - 40s 8ms/step - loss: 0.1055 - acc: 0.9605 - val_loss: 1.4241 - val_acc: 0.6451\n","\n","Epoch 00002: val_acc did not improve from 0.66041\n","Epoch 3/7\n","5266/5266 [==============================] - 40s 8ms/step - loss: 0.0689 - acc: 0.9772 - val_loss: 1.3254 - val_acc: 0.6399\n","\n","Epoch 00003: val_acc did not improve from 0.66041\n","Epoch 4/7\n","5266/5266 [==============================] - 40s 8ms/step - loss: 0.0456 - acc: 0.9821 - val_loss: 1.7216 - val_acc: 0.6365\n","\n","Epoch 00004: val_acc did not improve from 0.66041\n","Epoch 5/7\n","5266/5266 [==============================] - 40s 8ms/step - loss: 0.0434 - acc: 0.9820 - val_loss: 1.5168 - val_acc: 0.6331\n","\n","Epoch 00005: val_acc did not improve from 0.66041\n","Epoch 6/7\n","5266/5266 [==============================] - 40s 8ms/step - loss: 0.0304 - acc: 0.9859 - val_loss: 2.5212 - val_acc: 0.6451\n","\n","Epoch 00006: val_acc did not improve from 0.66041\n","Epoch 7/7\n","5266/5266 [==============================] - 40s 8ms/step - loss: 0.0412 - acc: 0.9812 - val_loss: 1.9586 - val_acc: 0.6348\n","\n","Epoch 00007: val_acc did not improve from 0.66041\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8H5pbaLt-ifY","colab_type":"code","colab":{}},"source":["w2=model2.predict(x_test) #predict on testing data for bi-gru with attention\n","w2=np.argmax(w2,axis=1)\n","w3=model3.predict(x_test) #predict on testing data for bi-lstm with attention\n","w3=np.argmax(w3,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJJR5YeR-rnQ","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIg93ZU8-tjV","colab_type":"code","colab":{}},"source":["#true labels for validation data\n","Y_actual=[]\n","for ix in y_test:\n","    Y_actual.append(np.argmax(ix))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMh8ahCU-4y_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"7f9d81a3-844f-49a9-e53d-c0b624a080b2"},"source":["print(\"Bi-GRU+ATTN\")\n","print(classification_report(Y_actual,w2))\n","print(\"Bi-LSTM+ATTN\")\n","print(classification_report(Y_actual,w3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GRU+ATTN\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.46      0.50       230\n","           1       0.68      0.76      0.72       356\n","\n","    accuracy                           0.64       586\n","   macro avg       0.62      0.61      0.61       586\n","weighted avg       0.63      0.64      0.63       586\n","\n","LSTM+ATTN\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.55      0.54       230\n","           1       0.70      0.69      0.70       356\n","\n","    accuracy                           0.63       586\n","   macro avg       0.62      0.62      0.62       586\n","weighted avg       0.64      0.63      0.64       586\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"woep8R4Ig3w_","colab_type":"code","colab":{}},"source":["#testing data\n","data_test=pd.read_csv('/content/drive/My Drive/minor/english_dataset/hasoc2019_en_test-2919_prepro.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXwxKFepiHPf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"172de160-86b3-45f9-8938-2aba8a629105"},"source":["data_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","      <th>task_2</th>\n","      <th>task_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hasoc_en_902</td>\n","      <td>west bengal doctor crisis protesting doctors a...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>hasoc_en_416</td>\n","      <td>68 5 million people forced leave homes read</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>hasoc_en_207</td>\n","      <td>came saw look fort good luck</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>hasoc_en_595</td>\n","      <td>get brexit delivered october 31st help build m...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>hasoc_en_568</td>\n","      <td>fuck go back dark ages cow ibnliverealtime rap...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>UNT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id  ... task_3\n","0  hasoc_en_902  ...   NONE\n","1  hasoc_en_416  ...   NONE\n","2  hasoc_en_207  ...   NONE\n","3  hasoc_en_595  ...   NONE\n","4  hasoc_en_568  ...    UNT\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"zenwxTGBiNjg","colab_type":"code","colab":{}},"source":["data_test.text=data_test.text.astype(str)\n","df_text=data_test['text']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5t5Qoe6miR0j","colab_type":"code","colab":{}},"source":["Column_Sequence=np.array(data_test[\"text\"],dtype=\"str\")\n","fresh=[]\n","for ix in Column_Sequence:\n","    sen=ix.lower()\n","    sen=Tokenizer.tokenize(sen)    #use the reg exp tokenizer object for text to make a list of strings and lowercase text (earlier also removed stopwords but that has been moved to preprocessing code)\n","    wordss=[(Word) for Word in sen]\n","    sentance=\" \".join(wordss)\n","    fresh.append(sentance)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXLufNLri7Ii","colab_type":"code","colab":{}},"source":["tokenizer = keras_text.Tokenizer(char_level = False,lower=True)  #create a kerastokenizer object\n","t=tokenizer.fit_on_texts(list(fresh))\n","list_tokenized_train = tokenizer.texts_to_sequences(fresh)\n","X_test = keras_seq.pad_sequences(list_tokenized_train, maxlen=300,padding=\"post\") #maxlen padding 300"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ozSiKKNZi-PE","colab_type":"code","colab":{}},"source":["w_test2=model2.predict(X_test)  #predict class of testing data for bi-gru+attn\n","w_test2=np.argmax(w_test2,axis=1)\n","w_test3=model3.predict(X_test)  #predict class of testing data for bi-lstm+attn\n","w_test3=np.argmax(w_test3,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dZIpegQjVe8","colab_type":"code","colab":{}},"source":["data_test['task_1'] = data_test['task_1'].map({'HOF': 0, 'NOT': 1}) #map label strings to numbers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lox5m_cwjnPQ","colab_type":"code","colab":{}},"source":["y_test_actual=data_test['task_1']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMw4udgyjtzd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"3bca23ff-ddd5-43be-d694-fdf229719748"},"source":["print(\"Bi-GRU+ATTN\")\n","print(classification_report(y_test_actual,w_test2))\n","print(\"Bi-LSTM+ATTN\")\n","print(classification_report(y_test_actual,w_test3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GRU+ATTN\n","              precision    recall  f1-score   support\n","\n","           0       0.23      0.24      0.23       288\n","           1       0.74      0.73      0.74       865\n","\n","    accuracy                           0.61      1153\n","   macro avg       0.48      0.48      0.48      1153\n","weighted avg       0.61      0.61      0.61      1153\n","\n","LSTM+ATTN\n","              precision    recall  f1-score   support\n","\n","           0       0.25      0.32      0.28       288\n","           1       0.75      0.68      0.71       865\n","\n","    accuracy                           0.59      1153\n","   macro avg       0.50      0.50      0.49      1153\n","weighted avg       0.62      0.59      0.60      1153\n","\n"],"name":"stdout"}]}]}