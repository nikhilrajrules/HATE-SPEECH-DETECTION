{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"attention_task2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3QxoDFxRvZ2K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"ba69f2c3-f6b4-4e2d-f211-c5aa985c0230"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6stsQl9Qa_je","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"fa4b3e3a-96e9-4f34-f6bd-2495df920f95"},"source":["%tensorflow_version 1.x #use tensorflow magic to use version 1.x in colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NdDIMLMhyoHr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0afc4ad7-da16-44c3-b8d3-9eefb7c4b8f5"},"source":["#imports\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import io\n","from nltk.corpus import stopwords\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem.porter import PorterStemmer\n","from keras.preprocessing import text as keras_text, sequence as keras_seq\n","from keras.utils import np_utils\n","from keras.layers import Conv1D, GlobalMaxPooling1D\n","from keras.layers import Dense, Activation, Convolution1D, MaxPooling1D, Dropout, Flatten\n","from keras.models import Sequential, save_model\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Embedding\n","from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2lTN2bzPzHO2","colab_type":"code","colab":{}},"source":["#traning data\n","df_train=pd.read_csv(\"/content/drive/My Drive/minor/english_dataset/english_dataset_prepro.csv\")\n","df_train=df_train[df_train.task_2!=\"NONE\"] #remove rows where task2=NONE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CwQUqcNdNv1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"b4c134b1-4353-4bdc-dc40-ca2ecad8ea40"},"source":["df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","      <th>task_2</th>\n","      <th>task_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>hasoc_en_2</td>\n","      <td>politico remember clearly individual1 admitted...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>hasoc_en_8</td>\n","      <td>ados trendingnow blacklivesmatter justice fuck...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>hasoc_en_12</td>\n","      <td>don’t know much take 45 compulsive liar trump3...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>hasoc_en_16</td>\n","      <td>good work icc keep going destroy whole fucking...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>hasoc_en_24</td>\n","      <td>shameonicc 1 icc dhoni gloves vs 2 icc plannin...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id  ... task_3\n","1    hasoc_en_2  ...    TIN\n","7    hasoc_en_8  ...    TIN\n","11  hasoc_en_12  ...    TIN\n","15  hasoc_en_16  ...    TIN\n","23  hasoc_en_24  ...    TIN\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"SilkiBB6zJGA","colab_type":"code","colab":{}},"source":["Column_Sequence=np.array(df_train[\"text\"],dtype=\"str\") #storing value  of tweets or text in numpy array of strings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4Cv8RXLcNRA","colab_type":"code","colab":{}},"source":["Tokenizer=RegexpTokenizer(r\"\\w+[a-z]+\") #create a reg exp tokenizer object for text to make a list of strings and lowercase text (earlier also removed stopwords but that has been moved to preprocessing code)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCYO8WUSzK48","colab_type":"code","colab":{}},"source":["fresh=[]\n","for ix in Column_Sequence:\n","    sen=ix.lower()                        #lower case\n","    sen=Tokenizer.tokenize(sen)           #tokenize the sentences.\n","    wordss=[(Word) for Word in sen]\n","    sentance=\" \".join(wordss)\n","    fresh.append(sentance)                #append all in one."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQijZsYtzNAr","colab_type":"code","colab":{}},"source":["tokenizer = keras_text.Tokenizer(char_level = False,lower=True) #create a kerastokenizer object\n","t=tokenizer.fit_on_texts(list(fresh))                           #fit on training text\n","list_tokenized_train = tokenizer.texts_to_sequences(fresh)\n","X_t = keras_seq.pad_sequences(list_tokenized_train, maxlen=300,padding=\"post\") #maxlen after padding 300\n","word_index = tokenizer.word_index      #get a list of all tokens or words in the vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GsUTF2deTgZE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"a9e86fe8-ce3b-4d08-829d-7dace921d3b0"},"source":["#extract word2vec vectors for words in vocab\n","import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","#load word2vec vectors from file.\n","word_vectors = KeyedVectors.load_word2vec_format('/content/drive/My Drive/minor/wordtovec/GoogleNews-vectors-negative300.bin.gz', binary=True)\n","\n","EMBEDDING_DIM=300\n","vocabulary_size=len(word_index)+1\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector            #store the vector if found.\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)  #store a rndom vector if not found\n","\n","del(word_vectors)  #del word2vec vectors to free memory\n","\n","from keras.layers import Embedding\n","#create an embediing layer from word2vec vectors of our vocab\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xsmvQINM9aeI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5c635ed3-7243-46bc-86de-e5205d3972eb"},"source":["len(tokenizer.word_counts)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9499"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"iFk50bF-9acF","colab_type":"code","colab":{}},"source":["X_train=X_t      #training text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uws-4mjU9qep","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ad00af38-0345-4cc1-8bfc-b9b77ca66da1"},"source":["X_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2261, 300)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"7XYjg7oe9sAV","colab_type":"code","colab":{}},"source":["Y=df_train[\"task_2\"]   #labels of classes with strings."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJpxBhBY9vgw","colab_type":"code","colab":{}},"source":["Y = Y.map({'PRFN':0, 'OFFN': 1,'HATE':2})  #map the class names to numbers."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYN6U0ab90AG","colab_type":"code","colab":{}},"source":["# One-hot encode label\n","Y_train=np_utils.to_categorical(Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwkh_aL4912g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"697fb4b1-a176-407e-9ab1-4e207fb345d9"},"source":["Y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2261, 3)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"N-C4VvFF93V8","colab_type":"code","colab":{}},"source":["x_train, x_test, y_train, y_test = train_test_split(X_train,Y_train, test_size=0.10, random_state=42) #training validation split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHz7bwBp941M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8e084f1e-f033-4dd7-9758-bc5038dab252"},"source":["y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 3)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"2iRdenDb96VP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"418d5b52-7611-4a03-afd8-8937c4660823"},"source":["x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 300)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"YOhfz_lK97zo","colab_type":"code","colab":{}},"source":["max_len=300   #length of text sequence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBZ7wggajCRi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"24032af2-d1a6-4167-b556-2eeaf5f5190a"},"source":["x_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5201,  253,  592, ...,    0,    0,    0],\n","       [   6,   15, 1828, ...,    0,    0,    0],\n","       [1091, 6275, 1519, ...,    0,    0,    0],\n","       ...,\n","       [1652,  295,   30, ...,    0,    0,    0],\n","       [   2,  495,   30, ...,    0,    0,    0],\n","       [   4, 2114,  254, ...,    0,    0,    0]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"c0RCXnxrwL4l","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, Input , Layer\n","from keras.layers import Embedding, GRU, Bidirectional , Reshape, Dot\n","from keras.models import Sequential, Model\n","from keras.layers.merge import concatenate\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import Input\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils.vis_utils import plot_model\n","from keras.models import Model\n","from keras import metrics\n","from keras import backend as K\n","from keras.regularizers import l2\n","import tensorflow as tf\n","from keras import initializers ,constraints, regularizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LTIy8oM9wEAk","colab_type":"code","colab":{}},"source":["#implementation of attention layer in keras\n","def dot_product(x, kernel):\n","    \"\"\"\n","    Wrapper for dot product operation, in order to be compatible with both\n","    Theano and Tensorflow\n","    Args:\n","        x (): input\n","        kernel (): weights\n","    Returns:\n","    \"\"\"\n","    if K.backend() == 'tensorflow':\n","        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n","    else:\n","        return K.dot(x, kernel)\n","    \n","\n","class AttentionWithContext(Layer):\n","    \"\"\"\n","    Attention operation, with a context/query vector, for temporal data.\n","    Supports Masking.\n","    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n","    \"Hierarchical Attention Networks for Document Classification\"\n","    by using a context vector to assist the attention\n","    # Input shape\n","        3D tensor with shape: `(samples, steps, features)`.\n","    # Output shape\n","        2D tensor with shape: `(samples, features)`.\n","    How to use:\n","    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n","    The dimensions are inferred based on the output shape of the RNN.\n","    Note: The layer has been tested with Keras 2.0.6\n","    Example:\n","        model.add(LSTM(64, return_sequences=True))\n","        model.add(AttentionWithContext())\n","        # next add a Dense layer (for classification/regression) or whatever...\n","    \"\"\"\n","\n","    def __init__(self,\n","                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        super(AttentionWithContext, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight(shape=(input_shape[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","\n","        self.u = self.add_weight(shape=(input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        super(AttentionWithContext, self).build(input_shape)\n","\n","    def compute_mask(self, input, input_mask=None):\n","        # do not pass the mask to the next layers\n","        return None\n","\n","    def call(self, x, mask=None):\n","        uit = dot_product(x, self.W)\n","\n","        if self.bias:\n","            uit += self.b\n","\n","        uit = K.tanh(uit)\n","        ait = dot_product(uit, self.u)\n","\n","        a = K.exp(ait)\n","\n","        # apply mask after the exp. will be re-normalized next\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= K.cast(mask, K.floatx())\n","\n","        # in some cases especially in the early stages of training the sum may be almost zero\n","        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n","        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0], input_shape[-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ju2L7fVjiOB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":479},"outputId":"96f5823f-5a9d-4934-eb7a-5c49e574b97f"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, CuDNNGRU\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#BiGRU+ATTENTION\n","sequence_input2 = Input(shape=(max_len,), dtype='int32') #input layer\n","embedded_sequences2 = embedding_layer(sequence_input2)\n","gru1=Bidirectional(CuDNNGRU(128, return_sequences=True))(embedded_sequences2) #bidirectional gru layer optimized for gpu\n","gru2= Bidirectional(CuDNNGRU(128, return_sequences=True))(gru1)\n","attn_outs=AttentionWithContext()(gru2) #attention layer\n","l_dense2 = Dense(128, activation='relu')(attn_outs)\n","preds2 = Dense(3, activation='softmax')(l_dense2) #ouput layer\n","\n","model2 = Model(sequence_input2, preds2)\n","model2.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","print(\"Bi-GRU+ATTENTION\")\n","model2.summary()\n","cp2=ModelCheckpoint('model_gru_attn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","GRU\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 300)               0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 300, 300)          2850000   \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 300, 256)          330240    \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 300, 256)          296448    \n","_________________________________________________________________\n","attention_with_context_1 (At (None, 256)               66048     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 387       \n","=================================================================\n","Total params: 3,576,019\n","Trainable params: 3,576,019\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_riePM31kx0M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"02811762-aeca-4c59-aa4e-747320c1f028"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D, Bidirectional\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, CuDNNLSTM\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#BI-LSTM+ATTENTION\n","sequence_input3 = Input(shape=(max_len,), dtype='int32') #input layer\n","embedded_sequences3 = embedding_layer(sequence_input3)\n","lstm1 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(embedded_sequences3) #bi-directional lstm layer optimized for gpu\n","lstm2= Bidirectional(CuDNNLSTM(128, return_sequences=True))(lstm1)\n","attn_outs3=AttentionWithContext()(lstm2) #attention layer\n","l_dense3 = Dense(128, activation='relu')(attn_outs3)\n","preds3 = Dense(3, activation='softmax')(l_dense3) #output layer\n","\n","model3 = Model(sequence_input3, preds3)\n","model3.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","print(\"Bi-LSTM+Attention\")\n","model3.summary()\n","cp3=ModelCheckpoint('model_lstm_attn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LSTM\n","Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 300)               0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 300, 300)          2850000   \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 300, 256)          440320    \n","_________________________________________________________________\n","bidirectional_4 (Bidirection (None, 300, 256)          395264    \n","_________________________________________________________________\n","attention_with_context_2 (At (None, 256)               66048     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 3)                 387       \n","=================================================================\n","Total params: 3,784,915\n","Trainable params: 3,784,915\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"svJu2O-Qm9gQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":564},"outputId":"6f3e698d-cb93-4268-8a24-2f68e01a251e"},"source":["history2=model2.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=7, batch_size=32,callbacks=[cp2]) #train bigru with attention with checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 2034 samples, validate on 227 samples\n","Epoch 1/7\n","2034/2034 [==============================] - 11s 5ms/step - loss: 0.9161 - acc: 0.5929 - val_loss: 0.9273 - val_acc: 0.6211\n","\n","Epoch 00001: val_acc improved from -inf to 0.62115, saving model to model_gru_attn.hdf5\n","Epoch 2/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.7007 - acc: 0.6991 - val_loss: 1.0517 - val_acc: 0.5947\n","\n","Epoch 00002: val_acc did not improve from 0.62115\n","Epoch 3/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.4326 - acc: 0.8373 - val_loss: 1.2046 - val_acc: 0.5947\n","\n","Epoch 00003: val_acc did not improve from 0.62115\n","Epoch 4/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.2345 - acc: 0.9174 - val_loss: 1.5691 - val_acc: 0.5066\n","\n","Epoch 00004: val_acc did not improve from 0.62115\n","Epoch 5/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.1448 - acc: 0.9503 - val_loss: 1.8967 - val_acc: 0.5947\n","\n","Epoch 00005: val_acc did not improve from 0.62115\n","Epoch 6/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0931 - acc: 0.9720 - val_loss: 2.0204 - val_acc: 0.5463\n","\n","Epoch 00006: val_acc did not improve from 0.62115\n","Epoch 7/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0648 - acc: 0.9808 - val_loss: 2.0893 - val_acc: 0.5727\n","\n","Epoch 00007: val_acc did not improve from 0.62115\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hl296E72nu9w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"outputId":"5b353608-a9f0-482b-b9bd-dc328d69f5ab"},"source":["history3=model3.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=7, batch_size=32,callbacks=[cp3]) #train bilstm with attention with checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 2034 samples, validate on 227 samples\n","Epoch 1/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.5714 - acc: 0.7748 - val_loss: 1.3842 - val_acc: 0.5815\n","\n","Epoch 00001: val_acc improved from -inf to 0.58150, saving model to model_lstm_attn.hdf5\n","Epoch 2/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.1371 - acc: 0.9567 - val_loss: 1.3967 - val_acc: 0.5727\n","\n","Epoch 00002: val_acc did not improve from 0.58150\n","Epoch 3/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.0788 - acc: 0.9813 - val_loss: 1.6993 - val_acc: 0.5507\n","\n","Epoch 00003: val_acc did not improve from 0.58150\n","Epoch 4/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.0525 - acc: 0.9838 - val_loss: 2.1626 - val_acc: 0.5374\n","\n","Epoch 00004: val_acc did not improve from 0.58150\n","Epoch 5/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.0305 - acc: 0.9926 - val_loss: 2.0397 - val_acc: 0.5551\n","\n","Epoch 00005: val_acc did not improve from 0.58150\n","Epoch 6/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.0203 - acc: 0.9941 - val_loss: 2.2487 - val_acc: 0.5022\n","\n","Epoch 00006: val_acc did not improve from 0.58150\n","Epoch 7/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.0168 - acc: 0.9931 - val_loss: 2.3331 - val_acc: 0.5683\n","\n","Epoch 00007: val_acc did not improve from 0.58150\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8H5pbaLt-ifY","colab_type":"code","colab":{}},"source":["w2=model2.predict(x_test) #predict on testing data for bi-gru with attention\n","w2=np.argmax(w2,axis=1)\n","w3=model3.predict(x_test) #predict on testing data for bi-lstm with attention\n","w3=np.argmax(w3,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJJR5YeR-rnQ","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIg93ZU8-tjV","colab_type":"code","colab":{}},"source":["#true labels for validation data\n","Y_actual=[]\n","for ix in y_test:\n","    Y_actual.append(np.argmax(ix))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMh8ahCU-4y_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"a0369fec-ce33-40b1-ff3b-8d2b6152c21e"},"source":["print(\"Bi-GRU+Attention\")\n","print(classification_report(Y_actual,w2))\n","print(\"Bi-LSTM+Attention\")\n","print(classification_report(Y_actual,w3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GRU\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.64      0.61        72\n","           1       0.11      0.05      0.07        39\n","           2       0.65      0.72      0.69       116\n","\n","    accuracy                           0.58       227\n","   macro avg       0.45      0.47      0.45       227\n","weighted avg       0.53      0.58      0.55       227\n","\n","LSTM\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.72      0.63        72\n","           1       0.12      0.08      0.09        39\n","           2       0.67      0.64      0.65       116\n","\n","    accuracy                           0.57       227\n","   macro avg       0.45      0.48      0.46       227\n","weighted avg       0.54      0.57      0.55       227\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"woep8R4Ig3w_","colab_type":"code","colab":{}},"source":["#testing data\n","data_test=pd.read_csv('/content/drive/My Drive/minor/english_dataset/hasoc2019_en_test-2919_prepro.csv')\n","data_test=data_test[data_test.task_2!=\"NONE\"] #remove rows where task2=NONE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXwxKFepiHPf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"4b29c772-7c55-4bd9-90c5-dae5dbce2e86"},"source":["data_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","      <th>task_2</th>\n","      <th>task_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>hasoc_en_568</td>\n","      <td>fuck go back dark ages cow ibnliverealtime rap...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>UNT</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>hasoc_en_527</td>\n","      <td>jesus christ christian news illuminati changin...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>hasoc_en_137</td>\n","      <td>even true muslims supporting zakir knkmow prom...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>hasoc_en_606</td>\n","      <td>kerala halal course sickular bastion serve por...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>hasoc_en_246</td>\n","      <td>look sweetie it’s simple jain ask veg food get...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         text_id  ... task_3\n","4   hasoc_en_568  ...    UNT\n","9   hasoc_en_527  ...    TIN\n","10  hasoc_en_137  ...    TIN\n","11  hasoc_en_606  ...    TIN\n","12  hasoc_en_246  ...    TIN\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"zenwxTGBiNjg","colab_type":"code","colab":{}},"source":["data_test.text=data_test.text.astype(str)\n","df_text=data_test['text']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5t5Qoe6miR0j","colab_type":"code","colab":{}},"source":["Column_Sequence=np.array(data_test[\"text\"],dtype=\"str\")\n","fresh=[]\n","for ix in Column_Sequence:\n","    sen=ix.lower()\n","    sen=Tokenizer.tokenize(sen)    #use the reg exp tokenizer object for text to make a list of strings and lowercase text (earlier also removed stopwords but that has been moved to preprocessing code)\n","    wordss=[(Word) for Word in sen]\n","    sentance=\" \".join(wordss)\n","    fresh.append(sentance)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXLufNLri7Ii","colab_type":"code","colab":{}},"source":["tokenizer = keras_text.Tokenizer(char_level = False,lower=True) #create a kerastokenizer object\n","t=tokenizer.fit_on_texts(list(fresh))\n","list_tokenized_train = tokenizer.texts_to_sequences(fresh)\n","X_test = keras_seq.pad_sequences(list_tokenized_train, maxlen=300,padding=\"post\") #maxlen after padding 300"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ozSiKKNZi-PE","colab_type":"code","colab":{}},"source":["w_test2=model2.predict(X_test) #predict class of testing data for bi-gru+attn\n","w_test2=np.argmax(w_test2,axis=1)\n","w_test3=model3.predict(X_test)  #predict class of testing data for bi-lstm+attn\n","w_test3=np.argmax(w_test3,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dZIpegQjVe8","colab_type":"code","colab":{}},"source":["data_test['task_2'] = data_test['task_2'].map({'PRFN':0, 'OFFN': 1,'HATE':2}) #map label strings to numbers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lox5m_cwjnPQ","colab_type":"code","colab":{}},"source":["y_test_actual=data_test['task_2']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMw4udgyjtzd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"b11a24d2-2ffe-4c71-959a-a76b7ca26d63"},"source":["print(\"Bi-GRU+attention\")\n","print(classification_report(y_test_actual,w_test2))\n","print(\"Bi-LSTM+attention\")\n","print(classification_report(y_test_actual,w_test3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GRU\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.38      0.38        93\n","           1       0.22      0.11      0.15        71\n","           2       0.45      0.57      0.50       124\n","\n","    accuracy                           0.40       288\n","   macro avg       0.35      0.35      0.34       288\n","weighted avg       0.37      0.40      0.37       288\n","\n","LSTM\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.52      0.48        93\n","           1       0.25      0.18      0.21        71\n","           2       0.47      0.49      0.48       124\n","\n","    accuracy                           0.42       288\n","   macro avg       0.39      0.40      0.39       288\n","weighted avg       0.41      0.42      0.41       288\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U6RXRxZW8vZB","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}