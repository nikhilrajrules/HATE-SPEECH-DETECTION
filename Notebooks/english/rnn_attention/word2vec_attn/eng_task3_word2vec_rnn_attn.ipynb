{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"attention_task3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3QxoDFxRvZ2K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"2f9b0923-6f6e-490b-c8b2-feca781fe610"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6stsQl9Qa_je","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"98d56bf7-0231-4f4b-f5f9-813894a27706"},"source":["%tensorflow_version 1.x #use tensorflow magic to use version 1.x in colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NdDIMLMhyoHr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2325e092-d06e-41ff-d807-726a1741b5dc"},"source":["#imports\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import io\n","from nltk.corpus import stopwords\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem.porter import PorterStemmer\n","from keras.preprocessing import text as keras_text, sequence as keras_seq\n","from keras.utils import np_utils\n","from keras.layers import Conv1D, GlobalMaxPooling1D\n","from keras.layers import Dense, Activation, Convolution1D, MaxPooling1D, Dropout, Flatten\n","from keras.models import Sequential, save_model\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Embedding\n","from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2lTN2bzPzHO2","colab_type":"code","colab":{}},"source":["#traning data\n","df_train=pd.read_csv(\"/content/drive/My Drive/minor/english_dataset/english_dataset_prepro.csv\")\n","df_train=df_train[df_train.task_3!=\"NONE\"] #remove rows where task3=NONE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CwQUqcNdNv1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"b9698276-b9b8-4d79-8a3e-e7c6b745d313"},"source":["df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","      <th>task_2</th>\n","      <th>task_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>hasoc_en_2</td>\n","      <td>politico remember clearly individual1 admitted...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>hasoc_en_8</td>\n","      <td>ados trendingnow blacklivesmatter justice fuck...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>hasoc_en_12</td>\n","      <td>don’t know much take 45 compulsive liar trump3...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>hasoc_en_16</td>\n","      <td>good work icc keep going destroy whole fucking...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>hasoc_en_24</td>\n","      <td>shameonicc 1 icc dhoni gloves vs 2 icc plannin...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id  ... task_3\n","1    hasoc_en_2  ...    TIN\n","7    hasoc_en_8  ...    TIN\n","11  hasoc_en_12  ...    TIN\n","15  hasoc_en_16  ...    TIN\n","23  hasoc_en_24  ...    TIN\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"SilkiBB6zJGA","colab_type":"code","colab":{}},"source":["Column_Sequence=np.array(df_train[\"text\"],dtype=\"str\") #storing value  of tweets or text in numpy array of strings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4Cv8RXLcNRA","colab_type":"code","colab":{}},"source":["Tokenizer=RegexpTokenizer(r\"\\w+[a-z]+\") #create a reg exp tokenizer object for text to make a list of strings and lowercase text (earlier also removed stopwords but that has been moved to preprocessing code)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCYO8WUSzK48","colab_type":"code","colab":{}},"source":["fresh=[]\n","for ix in Column_Sequence:\n","    sen=ix.lower()                        #lower case\n","    sen=Tokenizer.tokenize(sen)           #tokenize the sentences.\n","    wordss=[(Word) for Word in sen]\n","    sentance=\" \".join(wordss)\n","    fresh.append(sentance)                #append all in one."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQijZsYtzNAr","colab_type":"code","colab":{}},"source":["tokenizer = keras_text.Tokenizer(char_level = False,lower=True) #create a kerastokenizer object\n","t=tokenizer.fit_on_texts(list(fresh))                           #fit on training text\n","list_tokenized_train = tokenizer.texts_to_sequences(fresh)\n","X_t = keras_seq.pad_sequences(list_tokenized_train, maxlen=300,padding=\"post\") #maxlen after padding 300\n","word_index = tokenizer.word_index      #get a list of all tokens or words in the vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GsUTF2deTgZE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"c9a6073a-5ee5-4ca9-c98a-7f057efb0969"},"source":["#extract word2vec vectors for words in vocab\n","import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","#load word2vec vectors from file.\n","word_vectors = KeyedVectors.load_word2vec_format('/content/drive/My Drive/minor/wordtovec/GoogleNews-vectors-negative300.bin.gz', binary=True)\n","\n","EMBEDDING_DIM=300\n","vocabulary_size=len(word_index)+1\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector            #store the vector if found.\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)  #store a rndom vector if not found\n","\n","del(word_vectors)  #del word2vec vectors to free memory\n","\n","from keras.layers import Embedding\n","#create an embediing layer from word2vec vectors of our vocab\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xsmvQINM9aeI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0f5434fc-502c-4014-ab5b-ef33dadb7eb0"},"source":["len(tokenizer.word_counts)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9499"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"iFk50bF-9acF","colab_type":"code","colab":{}},"source":["X_train=X_t      #training text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uws-4mjU9qep","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d2a899d7-0cf0-4ae7-ffb4-528f8060ec26"},"source":["X_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2261, 300)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"7XYjg7oe9sAV","colab_type":"code","colab":{}},"source":["Y=df_train[\"task_3\"]   #labels of classes with strings."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJpxBhBY9vgw","colab_type":"code","colab":{}},"source":["Y = Y.map({'UNT':0, 'TIN': 1})  #map the class names to numbers."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYN6U0ab90AG","colab_type":"code","colab":{}},"source":["# One-hot encode label\n","Y_train=np_utils.to_categorical(Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwkh_aL4912g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9a9bb324-e7b1-42da-aede-61b1fd07405c"},"source":["Y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2261, 2)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"N-C4VvFF93V8","colab_type":"code","colab":{}},"source":["x_train, x_test, y_train, y_test = train_test_split(X_train,Y_train, test_size=0.10, random_state=42) #training validation split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHz7bwBp941M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2adb0a61-aecd-47ef-fe68-a07780dd2239"},"source":["y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 2)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"2iRdenDb96VP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"238a58f4-c2ba-4aa1-b38b-638a76fafde7"},"source":["x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 300)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"YOhfz_lK97zo","colab_type":"code","colab":{}},"source":["max_len=300   #length of text sequence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBZ7wggajCRi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"397856f6-bda1-46b0-95f9-1572bde53631"},"source":["x_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5201,  253,  592, ...,    0,    0,    0],\n","       [   6,   15, 1828, ...,    0,    0,    0],\n","       [1091, 6275, 1519, ...,    0,    0,    0],\n","       ...,\n","       [1652,  295,   30, ...,    0,    0,    0],\n","       [   2,  495,   30, ...,    0,    0,    0],\n","       [   4, 2114,  254, ...,    0,    0,    0]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"c0RCXnxrwL4l","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, Input , Layer\n","from keras.layers import Embedding, GRU, Bidirectional , Reshape, Dot\n","from keras.models import Sequential, Model\n","from keras.layers.merge import concatenate\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import Input\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils.vis_utils import plot_model\n","from keras.models import Model\n","from keras import metrics\n","from keras import backend as K\n","from keras.regularizers import l2\n","import tensorflow as tf\n","from keras import initializers ,constraints, regularizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LTIy8oM9wEAk","colab_type":"code","colab":{}},"source":["#implementation of attention layer in keras\n","def dot_product(x, kernel):\n","    \"\"\"\n","    Wrapper for dot product operation, in order to be compatible with both\n","    Theano and Tensorflow\n","    Args:\n","        x (): input\n","        kernel (): weights\n","    Returns:\n","    \"\"\"\n","    if K.backend() == 'tensorflow':\n","        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n","    else:\n","        return K.dot(x, kernel)\n","    \n","\n","class AttentionWithContext(Layer):\n","    \"\"\"\n","    Attention operation, with a context/query vector, for temporal data.\n","    Supports Masking.\n","    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n","    \"Hierarchical Attention Networks for Document Classification\"\n","    by using a context vector to assist the attention\n","    # Input shape\n","        3D tensor with shape: `(samples, steps, features)`.\n","    # Output shape\n","        2D tensor with shape: `(samples, features)`.\n","    How to use:\n","    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n","    The dimensions are inferred based on the output shape of the RNN.\n","    Note: The layer has been tested with Keras 2.0.6\n","    Example:\n","        model.add(LSTM(64, return_sequences=True))\n","        model.add(AttentionWithContext())\n","        # next add a Dense layer (for classification/regression) or whatever...\n","    \"\"\"\n","\n","    def __init__(self,\n","                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        super(AttentionWithContext, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight(shape=(input_shape[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","\n","        self.u = self.add_weight(shape=(input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        super(AttentionWithContext, self).build(input_shape)\n","\n","    def compute_mask(self, input, input_mask=None):\n","        # do not pass the mask to the next layers\n","        return None\n","\n","    def call(self, x, mask=None):\n","        uit = dot_product(x, self.W)\n","\n","        if self.bias:\n","            uit += self.b\n","\n","        uit = K.tanh(uit)\n","        ait = dot_product(uit, self.u)\n","\n","        a = K.exp(ait)\n","\n","        # apply mask after the exp. will be re-normalized next\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= K.cast(mask, K.floatx())\n","\n","        # in some cases especially in the early stages of training the sum may be almost zero\n","        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n","        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0], input_shape[-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ju2L7fVjiOB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":479},"outputId":"09859bd8-54ee-4372-bbce-97decd18352f"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, CuDNNGRU\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#BiGRU+ATTENTION\n","sequence_input2 = Input(shape=(max_len,), dtype='int32') #input layer\n","embedded_sequences2 = embedding_layer(sequence_input2)\n","gru1=Bidirectional(CuDNNGRU(128, return_sequences=True))(embedded_sequences2) #bidirectional gru layer optimized for gpu\n","gru2= Bidirectional(CuDNNGRU(128, return_sequences=True))(gru1)\n","attn_outs=AttentionWithContext()(gru2) #attention layer\n","l_dense2 = Dense(128, activation='relu')(attn_outs)\n","preds2 = Dense(2, activation='softmax')(l_dense2) #ouput layer\n","\n","model2 = Model(sequence_input2, preds2)\n","model2.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","print(\"Bi-GRU+ATTENTION\")\n","model2.summary()\n","cp2=ModelCheckpoint('model_gru_attn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","GRU\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 300)               0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 300, 300)          2850000   \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 300, 256)          330240    \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 300, 256)          296448    \n","_________________________________________________________________\n","attention_with_context_1 (At (None, 256)               66048     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 3,575,890\n","Trainable params: 3,575,890\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_riePM31kx0M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"66c6f79e-2578-4374-af9f-153eee906bc5"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D, Bidirectional\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, CuDNNLSTM\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#BI-LSTM+ATTENTION\n","sequence_input3 = Input(shape=(max_len,), dtype='int32') #input layer\n","embedded_sequences3 = embedding_layer(sequence_input3)\n","lstm1 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(embedded_sequences3) #bi-directional lstm layer optimized for gpu\n","lstm2= Bidirectional(CuDNNLSTM(128, return_sequences=True))(lstm1)\n","attn_outs3=AttentionWithContext()(lstm2) #attention layer\n","l_dense3 = Dense(128, activation='relu')(attn_outs3)\n","preds3 = Dense(2, activation='softmax')(l_dense3) #output layer\n","\n","model3 = Model(sequence_input3, preds3)\n","model3.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","print(\"Bi-LSTM+Attention\")\n","model3.summary()\n","cp3=ModelCheckpoint('model_lstm_attn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LSTM\n","Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 300)               0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 300, 300)          2850000   \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 300, 256)          440320    \n","_________________________________________________________________\n","bidirectional_4 (Bidirection (None, 300, 256)          395264    \n","_________________________________________________________________\n","attention_with_context_2 (At (None, 256)               66048     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 3,784,786\n","Trainable params: 3,784,786\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"svJu2O-Qm9gQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":564},"outputId":"b6c264e6-04c3-4556-d169-4f66903db2f3"},"source":["history2=model2.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=7, batch_size=32,callbacks=[cp2]) #train bigru with attention with checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 2034 samples, validate on 227 samples\n","Epoch 1/7\n","2034/2034 [==============================] - 11s 5ms/step - loss: 0.3318 - acc: 0.8948 - val_loss: 0.3384 - val_acc: 0.8811\n","\n","Epoch 00001: val_acc improved from -inf to 0.88106, saving model to model_gru_attn.hdf5\n","Epoch 2/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.2313 - acc: 0.9164 - val_loss: 0.3893 - val_acc: 0.8811\n","\n","Epoch 00002: val_acc did not improve from 0.88106\n","Epoch 3/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0915 - acc: 0.9646 - val_loss: 0.4098 - val_acc: 0.8722\n","\n","Epoch 00003: val_acc did not improve from 0.88106\n","Epoch 4/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0478 - acc: 0.9857 - val_loss: 0.4829 - val_acc: 0.8811\n","\n","Epoch 00004: val_acc did not improve from 0.88106\n","Epoch 5/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0280 - acc: 0.9916 - val_loss: 0.6487 - val_acc: 0.8238\n","\n","Epoch 00005: val_acc did not improve from 0.88106\n","Epoch 6/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0221 - acc: 0.9941 - val_loss: 0.7487 - val_acc: 0.7930\n","\n","Epoch 00006: val_acc did not improve from 0.88106\n","Epoch 7/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0172 - acc: 0.9961 - val_loss: 0.7452 - val_acc: 0.8458\n","\n","Epoch 00007: val_acc did not improve from 0.88106\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hl296E72nu9w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"outputId":"7d71630b-b917-495d-a3af-5960fe511ecd"},"source":["history3=model3.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=7, batch_size=32,callbacks=[cp3]) #train bilstm with attention with checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 2034 samples, validate on 227 samples\n","Epoch 1/7\n","2034/2034 [==============================] - 5s 2ms/step - loss: 0.2292 - acc: 0.9317 - val_loss: 0.8217 - val_acc: 0.7577\n","\n","Epoch 00001: val_acc improved from -inf to 0.75771, saving model to model_lstm_attn.hdf5\n","Epoch 2/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0458 - acc: 0.9853 - val_loss: 0.6010 - val_acc: 0.8458\n","\n","Epoch 00002: val_acc improved from 0.75771 to 0.84582, saving model to model_lstm_attn.hdf5\n","Epoch 3/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0138 - acc: 0.9975 - val_loss: 0.8296 - val_acc: 0.8326\n","\n","Epoch 00003: val_acc did not improve from 0.84582\n","Epoch 4/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0191 - acc: 0.9966 - val_loss: 0.6631 - val_acc: 0.8018\n","\n","Epoch 00004: val_acc did not improve from 0.84582\n","Epoch 5/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0095 - acc: 0.9966 - val_loss: 1.0157 - val_acc: 0.8502\n","\n","Epoch 00005: val_acc improved from 0.84582 to 0.85022, saving model to model_lstm_attn.hdf5\n","Epoch 6/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0050 - acc: 0.9975 - val_loss: 0.9579 - val_acc: 0.8590\n","\n","Epoch 00006: val_acc improved from 0.85022 to 0.85903, saving model to model_lstm_attn.hdf5\n","Epoch 7/7\n","2034/2034 [==============================] - 4s 2ms/step - loss: 0.0031 - acc: 0.9980 - val_loss: 1.0351 - val_acc: 0.8238\n","\n","Epoch 00007: val_acc did not improve from 0.85903\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8H5pbaLt-ifY","colab_type":"code","colab":{}},"source":["w2=model2.predict(x_test) #predict on testing data for bi-gru with attention\n","w2=np.argmax(w2,axis=1)\n","w3=model3.predict(x_test) #predict on testing data for bi-lstm with attention\n","w3=np.argmax(w3,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJJR5YeR-rnQ","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIg93ZU8-tjV","colab_type":"code","colab":{}},"source":["#true labels for validation data\n","Y_actual=[]\n","for ix in y_test:\n","    Y_actual.append(np.argmax(ix))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMh8ahCU-4y_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"787137c9-566d-4793-ae53-91e2420bd3a5"},"source":["print(\"Bi-GRU+Attention\")\n","print(classification_report(Y_actual,w2))\n","print(\"Bi-LSTM+Attention\")\n","print(classification_report(Y_actual,w3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GRU\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        25\n","           1       0.89      0.96      0.92       202\n","\n","    accuracy                           0.85       227\n","   macro avg       0.44      0.48      0.46       227\n","weighted avg       0.79      0.85      0.82       227\n","\n","LSTM\n","              precision    recall  f1-score   support\n","\n","           0       0.17      0.16      0.17        25\n","           1       0.90      0.91      0.90       202\n","\n","    accuracy                           0.82       227\n","   macro avg       0.54      0.53      0.53       227\n","weighted avg       0.82      0.82      0.82       227\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"woep8R4Ig3w_","colab_type":"code","colab":{}},"source":["#testing data\n","data_test=pd.read_csv('/content/drive/My Drive/minor/english_dataset/hasoc2019_en_test-2919_prepro.csv')\n","data_test=data_test[data_test.task_3!=\"NONE\"] #remove rows where task3=NONE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXwxKFepiHPf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"3acaa626-076c-489e-a53d-13b4639511a3"},"source":["data_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","      <th>task_2</th>\n","      <th>task_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>hasoc_en_568</td>\n","      <td>fuck go back dark ages cow ibnliverealtime rap...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>UNT</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>hasoc_en_527</td>\n","      <td>jesus christ christian news illuminati changin...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>hasoc_en_137</td>\n","      <td>even true muslims supporting zakir knkmow prom...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>hasoc_en_606</td>\n","      <td>kerala halal course sickular bastion serve por...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>hasoc_en_246</td>\n","      <td>look sweetie it’s simple jain ask veg food get...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         text_id  ... task_3\n","4   hasoc_en_568  ...    UNT\n","9   hasoc_en_527  ...    TIN\n","10  hasoc_en_137  ...    TIN\n","11  hasoc_en_606  ...    TIN\n","12  hasoc_en_246  ...    TIN\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"zenwxTGBiNjg","colab_type":"code","colab":{}},"source":["data_test.text=data_test.text.astype(str)\n","df_text=data_test['text']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5t5Qoe6miR0j","colab_type":"code","colab":{}},"source":["Column_Sequence=np.array(data_test[\"text\"],dtype=\"str\")\n","fresh=[]\n","for ix in Column_Sequence:\n","    sen=ix.lower()\n","    sen=Tokenizer.tokenize(sen)    #use the reg exp tokenizer object for text to make a list of strings and lowercase text (earlier also removed stopwords but that has been moved to preprocessing code)\n","    wordss=[(Word) for Word in sen]\n","    sentance=\" \".join(wordss)\n","    fresh.append(sentance)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXLufNLri7Ii","colab_type":"code","colab":{}},"source":["tokenizer = keras_text.Tokenizer(char_level = False,lower=True)  #create a kerastokenizer object\n","t=tokenizer.fit_on_texts(list(fresh))\n","list_tokenized_train = tokenizer.texts_to_sequences(fresh)\n","X_test = keras_seq.pad_sequences(list_tokenized_train, maxlen=300,padding=\"post\") #len after padding 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ozSiKKNZi-PE","colab_type":"code","colab":{}},"source":["w_test2=model2.predict(X_test) #predict class of testing data for bi-gru+attn\n","w_test2=np.argmax(w_test2,axis=1)\n","w_test3=model3.predict(X_test)  #predict class of testing data for bi-lstm+attn\n","w_test3=np.argmax(w_test3,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dZIpegQjVe8","colab_type":"code","colab":{}},"source":["data_test['task_3'] = data_test['task_3'].map({'UNT':0, 'TIN': 1}) #map label strings to numbers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lox5m_cwjnPQ","colab_type":"code","colab":{}},"source":["y_test_actual=data_test['task_3']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMw4udgyjtzd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"255b0bb8-3b88-4083-965c-d2fee7b38c49"},"source":["print(\"Bi-GRU+attention\")\n","print(classification_report(y_test_actual,w_test2))\n","print(\"Bi-LSTM+attention\")\n","print(classification_report(y_test_actual,w_test3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GRU\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        43\n","           1       0.85      1.00      0.92       245\n","\n","    accuracy                           0.85       288\n","   macro avg       0.43      0.50      0.46       288\n","weighted avg       0.72      0.85      0.78       288\n","\n","LSTM\n","              precision    recall  f1-score   support\n","\n","           0       0.11      0.05      0.06        43\n","           1       0.85      0.93      0.89       245\n","\n","    accuracy                           0.80       288\n","   macro avg       0.48      0.49      0.48       288\n","weighted avg       0.74      0.80      0.76       288\n","\n"],"name":"stdout"}]}]}