{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word2vec_task1.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1msTDMGzPE5gO2hmYgBfdjphHTjxIhiRO","authorship_tag":"ABX9TyNJBeOSJGfQ/hqrM2kXCOKC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6stsQl9Qa_je","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593401666676,"user_tz":-330,"elapsed":1478,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"a56bff3f-fa41-4765-f1fa-66a998478616"},"source":["%tensorflow_version 1.x #use tensorflow magic to use version 1.x in colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NdDIMLMhyoHr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593401669686,"user_tz":-330,"elapsed":4454,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"03be6b78-0a43-4670-8b84-0cebbc7c5962"},"source":["#imports\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import io\n","from nltk.corpus import stopwords\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem.porter import PorterStemmer\n","from keras.preprocessing import text as keras_text, sequence as keras_seq\n","from keras.utils import np_utils\n","from keras.layers import Conv1D, GlobalMaxPooling1D\n","from keras.layers import Dense, Activation, Convolution1D, MaxPooling1D, Dropout, Flatten\n","from keras.models import Sequential, save_model\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Embedding\n","from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2lTN2bzPzHO2","colab_type":"code","colab":{}},"source":["#traning data\n","df_train=pd.read_csv(\"/content/drive/My Drive/minor/english_dataset/english_dataset_prepro.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CwQUqcNdNv1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593401669694,"user_tz":-330,"elapsed":4423,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"0d701777-f567-4db3-a600-892cb148ce5e"},"source":["df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","      <th>task_2</th>\n","      <th>task_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hasoc_en_1</td>\n","      <td>dhonikeepstheglove watch sports minister kiren...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>hasoc_en_2</td>\n","      <td>politico remember clearly individual1 admitted...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>hasoc_en_3</td>\n","      <td>cricketworldcup guess would winner cwc19 team ...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>hasoc_en_4</td>\n","      <td>corbyn politically intellectual borisjohnsonsh...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>hasoc_en_5</td>\n","      <td>best teamindia another swimming competition su...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      text_id                                               text  ... task_2 task_3\n","0  hasoc_en_1  dhonikeepstheglove watch sports minister kiren...  ...   NONE   NONE\n","1  hasoc_en_2  politico remember clearly individual1 admitted...  ...   HATE    TIN\n","2  hasoc_en_3  cricketworldcup guess would winner cwc19 team ...  ...   NONE   NONE\n","3  hasoc_en_4  corbyn politically intellectual borisjohnsonsh...  ...   NONE   NONE\n","4  hasoc_en_5  best teamindia another swimming competition su...  ...   NONE   NONE\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"SilkiBB6zJGA","colab_type":"code","colab":{}},"source":["Column_Sequence=np.array(df_train[\"text\"],dtype=\"str\") #storing value  of tweets or text in numpy array of strings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4Cv8RXLcNRA","colab_type":"code","colab":{}},"source":["Tokenizer=RegexpTokenizer(r\"\\w+[a-z]+\") #create a reg exp tokenizer object for text to make a list of strings and lowercase text (earlier also removed stopwords but that has been moved to preprocessing code)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCYO8WUSzK48","colab_type":"code","colab":{}},"source":["fresh=[]\n","for ix in Column_Sequence:\n","    sen=ix.lower()                        #lower case\n","    sen=Tokenizer.tokenize(sen)           #tokenize the sentences.\n","    wordss=[(Word) for Word in sen]\n","    sentance=\" \".join(wordss)\n","    fresh.append(sentance)                #append all in one."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQijZsYtzNAr","colab_type":"code","colab":{}},"source":["tokenizer = keras_text.Tokenizer(char_level = False,lower=True) #create a kerastokenizer object\n","t=tokenizer.fit_on_texts(list(fresh))                           #fit on training text\n","list_tokenized_train = tokenizer.texts_to_sequences(fresh)\n","X_t = keras_seq.pad_sequences(list_tokenized_train, maxlen=300,padding=\"post\") #maxlen after padding 300\n","word_index = tokenizer.word_index      #get a list of all tokens or words in the vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GsUTF2deTgZE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1593401763293,"user_tz":-330,"elapsed":97934,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"ecff026c-c44b-4037-dfc3-5f5861e6572e"},"source":["#extract word2vec vectors for words in vocab\n","import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","#load word2vec vectors from file.\n","word_vectors = KeyedVectors.load_word2vec_format('/content/drive/My Drive/minor/wordtovec/GoogleNews-vectors-negative300.bin.gz', binary=True)\n","\n","EMBEDDING_DIM=300\n","vocabulary_size=len(word_index)+1\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector            #store the vector if found.\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)  #store a rndom vector if not found\n","\n","del(word_vectors)  #del word2vec vectors to free memory\n","\n","from keras.layers import Embedding\n","#create an embediing layer from word2vec vectors of our vocab\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xsmvQINM9aeI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593401763295,"user_tz":-330,"elapsed":97913,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"2603c93d-36fd-4a35-f623-aa4f289fb93b"},"source":["len(tokenizer.word_counts)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16526"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"iFk50bF-9acF","colab_type":"code","colab":{}},"source":["X_train=X_t       #training text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uws-4mjU9qep","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593401763298,"user_tz":-330,"elapsed":97879,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"b83d68f6-f357-4d63-c064-7fb69d215038"},"source":["X_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5852, 300)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"7XYjg7oe9sAV","colab_type":"code","colab":{}},"source":["Y=df_train[\"task_1\"]    #labels of classes with strings."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJpxBhBY9vgw","colab_type":"code","colab":{}},"source":["Y = Y.map({'HOF':0, 'NOT': 1})   #map the class names to numbers."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYN6U0ab90AG","colab_type":"code","colab":{}},"source":["# One-hot encode label\n","Y_train=np_utils.to_categorical(Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwkh_aL4912g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593401763302,"user_tz":-330,"elapsed":97801,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"89059124-1900-444f-a238-88b073c0173b"},"source":["Y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5852, 2)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"N-C4VvFF93V8","colab_type":"code","colab":{}},"source":["x_train, x_test, y_train, y_test = train_test_split(X_train,Y_train, test_size=0.10, random_state=42) #training validation split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHz7bwBp941M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593401763304,"user_tz":-330,"elapsed":97763,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"67ea26f4-c15f-4478-d30a-b9639c3a9ac2"},"source":["y_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5266, 2)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"2iRdenDb96VP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593401763306,"user_tz":-330,"elapsed":97743,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"4d674608-1f1e-4d52-de4e-52fc244fcb45"},"source":["x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5266, 300)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"YOhfz_lK97zo","colab_type":"code","colab":{}},"source":["max_len=300   #length of text sequence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBZ7wggajCRi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1593401763309,"user_tz":-330,"elapsed":97704,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"c936adb9-0014-4085-d32a-f6955c3072d5"},"source":["x_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    4,    21,   188, ...,     0,     0,     0],\n","       [ 1495,  1247,    70, ...,     0,     0,     0],\n","       [ 9400,  9401,  2422, ...,     0,     0,     0],\n","       ...,\n","       [ 3805,  2826, 15341, ...,     0,     0,     0],\n","       [  665, 15679,   968, ...,     0,     0,     0],\n","       [  382,  3152,  8291, ...,     0,     0,     0]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"_AIFLfInbZY0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":649},"executionInfo":{"status":"ok","timestamp":1593401766454,"user_tz":-330,"elapsed":100829,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"e5288646-1109-494f-8a19-6ec4a8380cf9"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D\n","from keras.layers import Conv1D, MaxPooling1D, Embedding\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#CNN\n","sequence_input1 = Input(shape=(max_len,), dtype='int32')  #input layer\n","embedded_sequences1 = embedding_layer(sequence_input1)\n","l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences1)\n","l_pool1 = MaxPooling1D(5)(l_cov1)\n","l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n","l_pool2 = MaxPooling1D(5)(l_cov2)\n","l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n","l_pool3 = MaxPooling1D(5)(l_cov3)  # global max pooling\n","l_flat1 = Flatten()(l_pool3)\n","l_dense1 = Dense(128, activation='relu')(l_flat1)\n","preds1 = Dense(2, activation='softmax')(l_dense1)        #output layer\n","\n","model1 = Model(sequence_input1, preds1)\n","model1.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['acc'])\n","\n","print(\"Simplified convolutional neural network\")\n","model1.summary()\n","cp1=ModelCheckpoint('model_cnn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)  #callback checkpoint\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Simplified convolutional neural network\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 300)               0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 300, 300)          4958100   \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 296, 128)          192128    \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 59, 128)           0         \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 55, 128)           82048     \n","_________________________________________________________________\n","max_pooling1d_2 (MaxPooling1 (None, 11, 128)           0         \n","_________________________________________________________________\n","conv1d_3 (Conv1D)            (None, 7, 128)            82048     \n","_________________________________________________________________\n","max_pooling1d_3 (MaxPooling1 (None, 1, 128)            0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               16512     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 5,331,094\n","Trainable params: 372,994\n","Non-trainable params: 4,958,100\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9ju2L7fVjiOB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1593401767193,"user_tz":-330,"elapsed":101522,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"d5b982db-d582-4495-8185-586b606bafcf"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D, GlobalAveragePooling1D\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, CuDNNGRU, Bidirectional, concatenate\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#BiGRU\n","sequence_input2 = Input(shape=(max_len,), dtype='int32') #input layer\n","embedded_sequences2 = embedding_layer(sequence_input2)\n","gru1=Bidirectional(CuDNNGRU(128, return_sequences=True))(embedded_sequences2)  #gpu optimized gru layer with a bi-directional layer\n","gru2= Bidirectional(CuDNNGRU(128, return_sequences=True))(gru1)\n","avg_pool = GlobalAveragePooling1D()(gru2)\n","max_pool = GlobalMaxPooling1D()(gru2)\n","conc = concatenate([avg_pool, max_pool])\n","l_dense2 = Dense(128, activation='relu')(conc)\n","preds2 = Dense(2, activation='softmax')(l_dense2)  #output layer\n","\n","model2 = Model(sequence_input2, preds2)\n","model2.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","print(\"GRU\")\n","model2.summary()\n","cp2=ModelCheckpoint('model_gru.hdf5',monitor='val_accuracy',verbose=1,save_best_only=True) #callback checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GRU\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 300)          0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 300, 300)     4958100     input_2[0][0]                    \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 300, 256)     330240      embedding_1[1][0]                \n","__________________________________________________________________________________________________\n","bidirectional_2 (Bidirectional) (None, 300, 256)     296448      bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","global_average_pooling1d_1 (Glo (None, 256)          0           bidirectional_2[0][0]            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 256)          0           bidirectional_2[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 512)          0           global_average_pooling1d_1[0][0] \n","                                                                 global_max_pooling1d_1[0][0]     \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 128)          65664       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 2)            258         dense_3[0][0]                    \n","==================================================================================================\n","Total params: 5,650,710\n","Trainable params: 692,610\n","Non-trainable params: 4,958,100\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_riePM31kx0M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1593401767892,"user_tz":-330,"elapsed":102190,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"3398c351-dbe7-4ef0-a893-efc0e550105f"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D, CuDNNLSTM, GlobalAveragePooling1D\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, Bidirectional, concatenate\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#Bi-LSTM\n","sequence_input3 = Input(shape=(max_len,), dtype='int32') #input layer\n","embedded_sequences3 = embedding_layer(sequence_input3)\n","lstm1 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(embedded_sequences3) #gpu optimized lstm layer with a bi-directional layer\n","lstm2= Bidirectional(CuDNNLSTM(128, return_sequences=True))(lstm1)\n","avg_pool = GlobalAveragePooling1D()(lstm2)\n","max_pool = GlobalMaxPooling1D()(lstm2)\n","conc = concatenate([avg_pool, max_pool])\n","l_dense3 = Dense(128, activation='relu')(conc)\n","preds3 = Dense(2, activation='softmax')(l_dense3) #output layer\n","\n","model3 = Model(sequence_input3, preds3)\n","model3.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","print(\"LSTM\")\n","model3.summary()\n","cp3=ModelCheckpoint('model_lstm.hdf5',monitor='val_accuracy',verbose=1,save_best_only=True) #callback checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LSTM\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 300)          0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 300, 300)     4958100     input_3[0][0]                    \n","__________________________________________________________________________________________________\n","bidirectional_3 (Bidirectional) (None, 300, 256)     440320      embedding_1[2][0]                \n","__________________________________________________________________________________________________\n","bidirectional_4 (Bidirectional) (None, 300, 256)     395264      bidirectional_3[0][0]            \n","__________________________________________________________________________________________________\n","global_average_pooling1d_2 (Glo (None, 256)          0           bidirectional_4[0][0]            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 256)          0           bidirectional_4[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 512)          0           global_average_pooling1d_2[0][0] \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 128)          65664       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 2)            258         dense_5[0][0]                    \n","==================================================================================================\n","Total params: 5,859,606\n","Trainable params: 901,506\n","Non-trainable params: 4,958,100\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8QiZgXzgeLH1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593401785195,"user_tz":-330,"elapsed":119463,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"41325dab-6768-40fd-a0ca-6fd6b21ab418"},"source":["history1=model1.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=15, batch_size=32,callbacks=[cp1]) #training cnn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 5266 samples, validate on 586 samples\n","Epoch 1/15\n","5266/5266 [==============================] - 3s 527us/step - loss: 0.6514 - acc: 0.6231 - val_loss: 0.6330 - val_acc: 0.6348\n","\n","Epoch 00001: val_acc improved from -inf to 0.63481, saving model to model_cnn.hdf5\n","Epoch 2/15\n","5266/5266 [==============================] - 1s 194us/step - loss: 0.5748 - acc: 0.7070 - val_loss: 0.6779 - val_acc: 0.6007\n","\n","Epoch 00002: val_acc did not improve from 0.63481\n","Epoch 3/15\n","5266/5266 [==============================] - 1s 188us/step - loss: 0.4188 - acc: 0.8118 - val_loss: 0.8247 - val_acc: 0.6195\n","\n","Epoch 00003: val_acc did not improve from 0.63481\n","Epoch 4/15\n","5266/5266 [==============================] - 1s 191us/step - loss: 0.3007 - acc: 0.8781 - val_loss: 0.8343 - val_acc: 0.6468\n","\n","Epoch 00004: val_acc improved from 0.63481 to 0.64676, saving model to model_cnn.hdf5\n","Epoch 5/15\n","5266/5266 [==============================] - 1s 191us/step - loss: 0.2130 - acc: 0.9201 - val_loss: 1.3484 - val_acc: 0.6382\n","\n","Epoch 00005: val_acc did not improve from 0.64676\n","Epoch 6/15\n","5266/5266 [==============================] - 1s 184us/step - loss: 0.1648 - acc: 0.9406 - val_loss: 1.1701 - val_acc: 0.6416\n","\n","Epoch 00006: val_acc did not improve from 0.64676\n","Epoch 7/15\n","5266/5266 [==============================] - 1s 187us/step - loss: 0.1644 - acc: 0.9468 - val_loss: 1.0279 - val_acc: 0.6126\n","\n","Epoch 00007: val_acc did not improve from 0.64676\n","Epoch 8/15\n","5266/5266 [==============================] - 1s 193us/step - loss: 0.1250 - acc: 0.9573 - val_loss: 1.1994 - val_acc: 0.6177\n","\n","Epoch 00008: val_acc did not improve from 0.64676\n","Epoch 9/15\n","5266/5266 [==============================] - 1s 187us/step - loss: 0.0997 - acc: 0.9618 - val_loss: 1.5839 - val_acc: 0.6314\n","\n","Epoch 00009: val_acc did not improve from 0.64676\n","Epoch 10/15\n","5266/5266 [==============================] - 1s 188us/step - loss: 0.1038 - acc: 0.9660 - val_loss: 1.4872 - val_acc: 0.6638\n","\n","Epoch 00010: val_acc improved from 0.64676 to 0.66382, saving model to model_cnn.hdf5\n","Epoch 11/15\n","5266/5266 [==============================] - 1s 189us/step - loss: 0.0791 - acc: 0.9728 - val_loss: 2.5411 - val_acc: 0.6433\n","\n","Epoch 00011: val_acc did not improve from 0.66382\n","Epoch 12/15\n","5266/5266 [==============================] - 1s 191us/step - loss: 0.0835 - acc: 0.9732 - val_loss: 2.0048 - val_acc: 0.6246\n","\n","Epoch 00012: val_acc did not improve from 0.66382\n","Epoch 13/15\n","5266/5266 [==============================] - 1s 190us/step - loss: 0.0819 - acc: 0.9763 - val_loss: 1.6005 - val_acc: 0.6433\n","\n","Epoch 00013: val_acc did not improve from 0.66382\n","Epoch 14/15\n","5266/5266 [==============================] - 1s 192us/step - loss: 0.0662 - acc: 0.9785 - val_loss: 2.6358 - val_acc: 0.6451\n","\n","Epoch 00014: val_acc did not improve from 0.66382\n","Epoch 15/15\n","5266/5266 [==============================] - 1s 191us/step - loss: 0.0895 - acc: 0.9746 - val_loss: 1.5177 - val_acc: 0.6570\n","\n","Epoch 00015: val_acc did not improve from 0.66382\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"svJu2O-Qm9gQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"status":"ok","timestamp":1593401855176,"user_tz":-330,"elapsed":189413,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"d8cc7528-da2c-4020-cf67-32c670c22892"},"source":["history2=model2.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=7, batch_size=32,callbacks=[cp2]) #training bi-gru"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 5266 samples, validate on 586 samples\n","Epoch 1/7\n","5266/5266 [==============================] - 10s 2ms/step - loss: 0.6432 - acc: 0.6310 - val_loss: 0.6036 - val_acc: 0.6792\n","\n","Epoch 00001: val_acc improved from -inf to 0.67918, saving model to model_gru.hdf5\n","Epoch 2/7\n","5266/5266 [==============================] - 10s 2ms/step - loss: 0.5846 - acc: 0.6897 - val_loss: 0.5958 - val_acc: 0.6962\n","\n","Epoch 00002: val_acc improved from 0.67918 to 0.69625, saving model to model_gru.hdf5\n","Epoch 3/7\n","5266/5266 [==============================] - 10s 2ms/step - loss: 0.5177 - acc: 0.7467 - val_loss: 0.6101 - val_acc: 0.6792\n","\n","Epoch 00003: val_acc did not improve from 0.69625\n","Epoch 4/7\n","5266/5266 [==============================] - 10s 2ms/step - loss: 0.4125 - acc: 0.8078 - val_loss: 0.6585 - val_acc: 0.6638\n","\n","Epoch 00004: val_acc did not improve from 0.69625\n","Epoch 5/7\n","5266/5266 [==============================] - 10s 2ms/step - loss: 0.2812 - acc: 0.8863 - val_loss: 0.7656 - val_acc: 0.6706\n","\n","Epoch 00005: val_acc did not improve from 0.69625\n","Epoch 6/7\n","5266/5266 [==============================] - 10s 2ms/step - loss: 0.1794 - acc: 0.9343 - val_loss: 0.8852 - val_acc: 0.6638\n","\n","Epoch 00006: val_acc did not improve from 0.69625\n","Epoch 7/7\n","5266/5266 [==============================] - 10s 2ms/step - loss: 0.1206 - acc: 0.9599 - val_loss: 0.9874 - val_acc: 0.6655\n","\n","Epoch 00007: val_acc did not improve from 0.69625\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hl296E72nu9w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"status":"ok","timestamp":1593401935112,"user_tz":-330,"elapsed":269321,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"9988ee00-bf96-41a1-d95c-b78d2f0e29e8"},"source":["history3=model3.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=7, batch_size=32,callbacks=[cp3]) #training bilstm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 5266 samples, validate on 586 samples\n","Epoch 1/7\n","5266/5266 [==============================] - 12s 2ms/step - loss: 0.6371 - acc: 0.6329 - val_loss: 0.6303 - val_acc: 0.6212\n","\n","Epoch 00001: val_acc improved from -inf to 0.62116, saving model to model_lstm.hdf5\n","Epoch 2/7\n","5266/5266 [==============================] - 11s 2ms/step - loss: 0.5948 - acc: 0.6895 - val_loss: 0.5803 - val_acc: 0.6980\n","\n","Epoch 00002: val_acc improved from 0.62116 to 0.69795, saving model to model_lstm.hdf5\n","Epoch 3/7\n","5266/5266 [==============================] - 11s 2ms/step - loss: 0.5481 - acc: 0.7235 - val_loss: 0.5996 - val_acc: 0.6945\n","\n","Epoch 00003: val_acc did not improve from 0.69795\n","Epoch 4/7\n","5266/5266 [==============================] - 11s 2ms/step - loss: 0.4790 - acc: 0.7689 - val_loss: 0.6444 - val_acc: 0.6638\n","\n","Epoch 00004: val_acc did not improve from 0.69795\n","Epoch 5/7\n","5266/5266 [==============================] - 11s 2ms/step - loss: 0.3821 - acc: 0.8314 - val_loss: 0.6927 - val_acc: 0.6706\n","\n","Epoch 00005: val_acc did not improve from 0.69795\n","Epoch 6/7\n","5266/5266 [==============================] - 11s 2ms/step - loss: 0.2804 - acc: 0.8819 - val_loss: 0.7805 - val_acc: 0.6382\n","\n","Epoch 00006: val_acc did not improve from 0.69795\n","Epoch 7/7\n","5266/5266 [==============================] - 11s 2ms/step - loss: 0.1969 - acc: 0.9216 - val_loss: 0.9431 - val_acc: 0.6621\n","\n","Epoch 00007: val_acc did not improve from 0.69795\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8H5pbaLt-ifY","colab_type":"code","colab":{}},"source":["w1=model1.predict(x_test) #predict on val data cnn\n","w1=np.argmax(w1,axis=1)\n","w2=model2.predict(x_test) #predict on val data bi-gru\n","w2=np.argmax(w2,axis=1)\n","w3=model3.predict(x_test) #predict on val data bi-lstm\n","w3=np.argmax(w3,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJJR5YeR-rnQ","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIg93ZU8-tjV","colab_type":"code","colab":{}},"source":["#true labels for val data\n","Y_actual=[]\n","for ix in y_test:\n","    Y_actual.append(np.argmax(ix))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMh8ahCU-4y_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1593401936432,"user_tz":-330,"elapsed":270556,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"16ed6034-aaeb-4f39-9965-ee9255192d81"},"source":["print(\"CNN\")\n","print(classification_report(Y_actual,w1))\n","print(\"BI-GRU\")\n","print(classification_report(Y_actual,w2))\n","print(\"BI-LSTM\")\n","print(classification_report(Y_actual,w3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CNN\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.57      0.56       230\n","           1       0.72      0.72      0.72       356\n","\n","    accuracy                           0.66       586\n","   macro avg       0.64      0.64      0.64       586\n","weighted avg       0.66      0.66      0.66       586\n","\n","BI-GRU\n","              precision    recall  f1-score   support\n","\n","           0       0.58      0.53      0.55       230\n","           1       0.71      0.76      0.73       356\n","\n","    accuracy                           0.67       586\n","   macro avg       0.65      0.64      0.64       586\n","weighted avg       0.66      0.67      0.66       586\n","\n","BI-LSTM\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.46      0.52       230\n","           1       0.69      0.79      0.74       356\n","\n","    accuracy                           0.66       586\n","   macro avg       0.64      0.63      0.63       586\n","weighted avg       0.65      0.66      0.65       586\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"woep8R4Ig3w_","colab_type":"code","colab":{}},"source":["data_test=pd.read_csv('/content/drive/My Drive/minor/english_dataset/hasoc2019_en_test-2919_prepro.csv') #testing data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXwxKFepiHPf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593401936434,"user_tz":-330,"elapsed":270509,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"2f100a6a-c8b1-460b-b642-cd0763a1902f"},"source":["data_test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","      <th>task_2</th>\n","      <th>task_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hasoc_en_902</td>\n","      <td>west bengal doctor crisis protesting doctors a...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>hasoc_en_416</td>\n","      <td>68 5 million people forced leave homes read</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>hasoc_en_207</td>\n","      <td>came saw look fort good luck</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>hasoc_en_595</td>\n","      <td>get brexit delivered october 31st help build m...</td>\n","      <td>NOT</td>\n","      <td>NONE</td>\n","      <td>NONE</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>hasoc_en_568</td>\n","      <td>fuck go back dark ages cow ibnliverealtime rap...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>UNT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id  ... task_3\n","0  hasoc_en_902  ...   NONE\n","1  hasoc_en_416  ...   NONE\n","2  hasoc_en_207  ...   NONE\n","3  hasoc_en_595  ...   NONE\n","4  hasoc_en_568  ...    UNT\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"zenwxTGBiNjg","colab_type":"code","colab":{}},"source":["data_test.text=data_test.text.astype(str)\n","df_text=data_test['text']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5t5Qoe6miR0j","colab_type":"code","colab":{}},"source":["Column_Sequence=np.array(data_test[\"text\"],dtype=\"str\")\n","fresh=[]\n","for ix in Column_Sequence:\n","    sen=ix.lower()\n","    sen=Tokenizer.tokenize(sen)    #use the reg exp tokenizer object for text to make a list of strings and lowercase text (earlier also removed stopwords but that has been moved to preprocessing code)\n","    wordss=[(Word) for Word in sen]\n","    sentance=\" \".join(wordss)\n","    fresh.append(sentance)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXLufNLri7Ii","colab_type":"code","colab":{}},"source":["tokenizer = keras_text.Tokenizer(char_level = False,lower=True) #create a kerastokenizer object\n","t=tokenizer.fit_on_texts(list(fresh))\n","list_tokenized_train = tokenizer.texts_to_sequences(fresh)\n","X_test = keras_seq.pad_sequences(list_tokenized_train, maxlen=300,padding=\"post\") #maxlen after padding 300"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ozSiKKNZi-PE","colab_type":"code","colab":{}},"source":["w_test1=model1.predict(X_test)     #predict class of testing data for cnn\n","w_test1=np.argmax(w_test1,axis=1)\n","w_test2=model2.predict(X_test)     #predict class of testing data for bi-gru\n","w_test2=np.argmax(w_test2,axis=1)\n","w_test3=model3.predict(X_test)     #predict class of testing data for bi-lstm\n","w_test3=np.argmax(w_test3,axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dZIpegQjVe8","colab_type":"code","colab":{}},"source":["data_test['task_1'] = data_test['task_1'].map({'HOF':0, 'NOT': 1}) #map label strings to numbers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lox5m_cwjnPQ","colab_type":"code","colab":{}},"source":["y_test_actual=data_test['task_1']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMw4udgyjtzd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1593401938426,"user_tz":-330,"elapsed":272336,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"ed8735d8-18f5-4f25-c59e-b67e8df930cb"},"source":["print(\"CNN\")\n","print(classification_report(y_test_actual,w_test1))\n","print(\"BI-GRU\")\n","print(classification_report(y_test_actual,w_test2))\n","print(\"BI-LSTM\")\n","print(classification_report(y_test_actual,w_test3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CNN\n","              precision    recall  f1-score   support\n","\n","           0       0.22      0.32      0.26       288\n","           1       0.73      0.63      0.68       865\n","\n","    accuracy                           0.55      1153\n","   macro avg       0.48      0.47      0.47      1153\n","weighted avg       0.61      0.55      0.57      1153\n","\n","BI-GRU\n","              precision    recall  f1-score   support\n","\n","           0       0.22      0.31      0.26       288\n","           1       0.74      0.65      0.69       865\n","\n","    accuracy                           0.56      1153\n","   macro avg       0.48      0.48      0.47      1153\n","weighted avg       0.61      0.56      0.58      1153\n","\n","BI-LSTM\n","              precision    recall  f1-score   support\n","\n","           0       0.27      0.31      0.29       288\n","           1       0.76      0.72      0.74       865\n","\n","    accuracy                           0.62      1153\n","   macro avg       0.51      0.51      0.51      1153\n","weighted avg       0.64      0.62      0.63      1153\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ynyPEXoqx1v4","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}