{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word2vec_task2.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1VFXHLVItvj64u14BN9Hm7j1i9Uue__X3","authorship_tag":"ABX9TyMH8Euh6RQdN6DVQ6XtiKWj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6stsQl9Qa_je","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593402929023,"user_tz":-330,"elapsed":1541,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"c89a9eb3-2e12-473b-f653-363399bc2de9"},"source":["%tensorflow_version 1.x #use tensorflow magic to use version 1.x in colab"],"execution_count":1,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x #use tensorflow magic to use version 1.x in colab`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NdDIMLMhyoHr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593402935761,"user_tz":-330,"elapsed":8253,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"6f550fb2-c6a2-4838-f0d7-a1b7cda41031"},"source":["#imports\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import io\n","from nltk.corpus import stopwords\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem.porter import PorterStemmer\n","from keras.preprocessing import text as keras_text, sequence as keras_seq\n","from keras.utils import np_utils\n","from keras.layers import Conv1D, GlobalMaxPooling1D\n","from keras.layers import Dense, Activation, Convolution1D, MaxPooling1D, Dropout, Flatten\n","from keras.models import Sequential, save_model\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Embedding\n","from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2lTN2bzPzHO2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593402937354,"user_tz":-330,"elapsed":9836,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["#training data\n","df_train=pd.read_csv(\"/content/drive/My Drive/minor/english_dataset/english_dataset_prepro.csv\")\n","#drop rows having value NONE in task 2\n","df_train=df_train[df_train.task_2!=\"NONE\"]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CwQUqcNdNv1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593402937357,"user_tz":-330,"elapsed":9819,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"3a1dd992-591f-4f6f-9a94-720becf32bd7"},"source":["df_train.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","      <th>task_2</th>\n","      <th>task_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>hasoc_en_2</td>\n","      <td>politico remember clearly individual1 admitted...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>hasoc_en_8</td>\n","      <td>ados trendingnow blacklivesmatter justice fuck...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>hasoc_en_12</td>\n","      <td>don’t know much take 45 compulsive liar trump3...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>hasoc_en_16</td>\n","      <td>good work icc keep going destroy whole fucking...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>hasoc_en_24</td>\n","      <td>shameonicc 1 icc dhoni gloves vs 2 icc plannin...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        text_id  ... task_3\n","1    hasoc_en_2  ...    TIN\n","7    hasoc_en_8  ...    TIN\n","11  hasoc_en_12  ...    TIN\n","15  hasoc_en_16  ...    TIN\n","23  hasoc_en_24  ...    TIN\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"SilkiBB6zJGA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593402937358,"user_tz":-330,"elapsed":9811,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["Column_Sequence=np.array(df_train[\"text\"],dtype=\"str\") #storing value  of tweets or text in numpy array of strings"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4Cv8RXLcNRA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593402937362,"user_tz":-330,"elapsed":9810,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["Tokenizer=RegexpTokenizer(r\"\\w+[a-z]+\") #create a reg exp tokenizer object for text to make a list of strings and lowercase text (earlier also removed stopwords but that has been moved to preprocessing code)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCYO8WUSzK48","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593402937364,"user_tz":-330,"elapsed":9805,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["fresh=[]\n","for ix in Column_Sequence:\n","    sen=ix.lower()                        #lower case\n","    sen=Tokenizer.tokenize(sen)           #tokenize the sentences.\n","    wordss=[(Word) for Word in sen]\n","    sentance=\" \".join(wordss)\n","    fresh.append(sentance)                #append all in one."],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQijZsYtzNAr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593402937365,"user_tz":-330,"elapsed":9799,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["tokenizer = keras_text.Tokenizer(char_level = False,lower=True) #create a kerastokenizer object\n","t=tokenizer.fit_on_texts(list(fresh))                           #fit on training text\n","list_tokenized_train = tokenizer.texts_to_sequences(fresh)\n","X_t = keras_seq.pad_sequences(list_tokenized_train, maxlen=300,padding=\"post\") #maxlen padding 100\n","word_index = tokenizer.word_index      #get a list of all tokens or words in the vocab"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"GsUTF2deTgZE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1593403058704,"user_tz":-330,"elapsed":131121,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"b048ed7a-7805-4cc8-ff78-714cf0056116"},"source":["#extract word2vec vectors for words in vocab\n","import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","#load word2vec vectors from file.\n","word_vectors = KeyedVectors.load_word2vec_format('/content/drive/My Drive/minor/wordtovec/GoogleNews-vectors-negative300.bin.gz', binary=True)\n","\n","EMBEDDING_DIM=300\n","vocabulary_size=len(word_index)+1\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector            #store the vector if found.\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)  #store a rndom vector if not found\n","\n","del(word_vectors)  #del word2vec vectors to free memory\n","\n","from keras.layers import Embedding\n","#create an embediing layer from word2vec vectors of our vocab\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=False)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xsmvQINM9aeI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593403058711,"user_tz":-330,"elapsed":131104,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"4912a2b1-31b4-4168-ba84-ff098dec9bb8"},"source":["len(tokenizer.word_counts)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9499"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"iFk50bF-9acF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403058712,"user_tz":-330,"elapsed":131097,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["X_train=X_t       #training text"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uws-4mjU9qep","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593403058713,"user_tz":-330,"elapsed":131073,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"16fd6ceb-d3a6-477b-bb11-2ee9ca2afbcf"},"source":["X_train.shape"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2261, 300)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"7XYjg7oe9sAV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403058715,"user_tz":-330,"elapsed":131067,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["Y=df_train[\"task_2\"]   #labels of classes with strings."],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJpxBhBY9vgw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403058716,"user_tz":-330,"elapsed":131060,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["Y = Y.map({'PRFN':0, 'OFFN': 1,'HATE':2})  #map the class names to numbers."],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYN6U0ab90AG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403058717,"user_tz":-330,"elapsed":131053,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["# One-hot encode label\n","Y_train=np_utils.to_categorical(Y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwkh_aL4912g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593403058718,"user_tz":-330,"elapsed":131024,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"22cb7860-1da3-4759-84c8-9d0fc44ec048"},"source":["Y_train.shape"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2261, 3)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"N-C4VvFF93V8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403058719,"user_tz":-330,"elapsed":131005,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["x_train, x_test, y_train, y_test = train_test_split(X_train,Y_train, test_size=0.10, random_state=42) #training and validation split of training data"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHz7bwBp941M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593403058720,"user_tz":-330,"elapsed":130977,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"eed30cc5-b1fa-495e-ee0b-4ee42e23acf6"},"source":["y_train.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 3)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"2iRdenDb96VP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593403058722,"user_tz":-330,"elapsed":130950,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"e4c9125f-2dbc-4395-e063-8f2ac479a886"},"source":["x_train.shape"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 300)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"YOhfz_lK97zo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403058723,"user_tz":-330,"elapsed":130946,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["max_len=300  #length of text sequence"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBZ7wggajCRi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1593403058724,"user_tz":-330,"elapsed":130910,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"d35720e1-513d-49ad-e08d-f699b278a39d"},"source":["x_train"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5201,  253,  592, ...,    0,    0,    0],\n","       [   6,   15, 1828, ...,    0,    0,    0],\n","       [1091, 6275, 1519, ...,    0,    0,    0],\n","       ...,\n","       [1652,  295,   30, ...,    0,    0,    0],\n","       [   2,  495,   30, ...,    0,    0,    0],\n","       [   4, 2114,  254, ...,    0,    0,    0]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"_AIFLfInbZY0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":649},"executionInfo":{"status":"ok","timestamp":1593403066303,"user_tz":-330,"elapsed":138460,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"c992e04e-5ac3-419a-8908-66d73181d416"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D\n","from keras.layers import Conv1D, MaxPooling1D, Embedding\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#CNN\n","sequence_input1 = Input(shape=(max_len,), dtype='int32')  #input layer\n","embedded_sequences1 = embedding_layer(sequence_input1)\n","l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences1)\n","l_pool1 = MaxPooling1D(5)(l_cov1)\n","l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n","l_pool2 = MaxPooling1D(5)(l_cov2)\n","l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n","l_pool3 = MaxPooling1D(5)(l_cov3)  # global max pooling\n","l_flat1 = Flatten()(l_pool3)\n","l_dense1 = Dense(128, activation='relu')(l_flat1)\n","preds1 = Dense(3, activation='softmax')(l_dense1)      #output layer\n","\n","model1 = Model(sequence_input1, preds1)\n","model1.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['acc'])\n","\n","print(\"Simplified convolutional neural network\")\n","model1.summary()\n","cp1=ModelCheckpoint('model_cnn.hdf5',monitor='val_acc',verbose=1,save_best_only=True) #callback checkpoint\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Simplified convolutional neural network\n","Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 300)               0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 300, 300)          2850000   \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 296, 128)          192128    \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 59, 128)           0         \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 55, 128)           82048     \n","_________________________________________________________________\n","max_pooling1d_2 (MaxPooling1 (None, 11, 128)           0         \n","_________________________________________________________________\n","conv1d_3 (Conv1D)            (None, 7, 128)            82048     \n","_________________________________________________________________\n","max_pooling1d_3 (MaxPooling1 (None, 1, 128)            0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               16512     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 387       \n","=================================================================\n","Total params: 3,223,123\n","Trainable params: 373,123\n","Non-trainable params: 2,850,000\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9ju2L7fVjiOB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1593403068509,"user_tz":-330,"elapsed":140638,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"29cfaa91-c618-41db-a21d-109dd9edc86b"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D, GlobalAveragePooling1D\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, CuDNNGRU, Bidirectional, concatenate\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#BiGRU\n","sequence_input2 = Input(shape=(max_len,), dtype='int32')   #input layer\n","embedded_sequences2 = embedding_layer(sequence_input2)\n","gru1=Bidirectional(CuDNNGRU(128, return_sequences=True))(embedded_sequences2)  #gpu optimized gru layer with a bi-directional layer\n","gru2= Bidirectional(CuDNNGRU(128, return_sequences=True))(gru1)\n","avg_pool = GlobalAveragePooling1D()(gru2)\n","max_pool = GlobalMaxPooling1D()(gru2)\n","conc = concatenate([avg_pool, max_pool])\n","l_dense2 = Dense(128, activation='relu')(conc)\n","preds2 = Dense(3, activation='softmax')(l_dense2)  #output layer\n","\n","model2 = Model(sequence_input2, preds2)\n","model2.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","print(\"GRU\")\n","model2.summary()\n","cp2=ModelCheckpoint('model_gru.hdf5',monitor='val_accuracy',verbose=1,save_best_only=True) #callback checkpoint"],"execution_count":23,"outputs":[{"output_type":"stream","text":["GRU\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 300)          0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 300, 300)     2850000     input_2[0][0]                    \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 300, 256)     330240      embedding_1[1][0]                \n","__________________________________________________________________________________________________\n","bidirectional_2 (Bidirectional) (None, 300, 256)     296448      bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","global_average_pooling1d_1 (Glo (None, 256)          0           bidirectional_2[0][0]            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 256)          0           bidirectional_2[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 512)          0           global_average_pooling1d_1[0][0] \n","                                                                 global_max_pooling1d_1[0][0]     \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 128)          65664       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 3)            387         dense_3[0][0]                    \n","==================================================================================================\n","Total params: 3,542,739\n","Trainable params: 692,739\n","Non-trainable params: 2,850,000\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_riePM31kx0M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1593403068514,"user_tz":-330,"elapsed":140621,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"db93510b-e5a7-4110-c52c-db9e4e426b39"},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D, CuDNNLSTM, GlobalAveragePooling1D\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, Bidirectional, concatenate\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","#Bi-LSTM\n","sequence_input3 = Input(shape=(max_len,), dtype='int32') #input layer\n","embedded_sequences3 = embedding_layer(sequence_input3)\n","lstm1 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(embedded_sequences3) #gpu optimized lstm layer with a bi-directional layer\n","lstm2= Bidirectional(CuDNNLSTM(128, return_sequences=True))(lstm1)\n","avg_pool = GlobalAveragePooling1D()(lstm2)\n","max_pool = GlobalMaxPooling1D()(lstm2)\n","conc = concatenate([avg_pool, max_pool])\n","l_dense3 = Dense(128, activation='relu')(conc)\n","preds3 = Dense(3, activation='softmax')(l_dense3) #output layer\n","\n","model3 = Model(sequence_input3, preds3)\n","model3.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['acc'])\n","\n","print(\"LSTM\")\n","model3.summary()\n","cp3=ModelCheckpoint('model_lstm.hdf5',monitor='val_accuracy',verbose=1,save_best_only=True) #callback checkpoint"],"execution_count":24,"outputs":[{"output_type":"stream","text":["LSTM\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 300)          0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 300, 300)     2850000     input_3[0][0]                    \n","__________________________________________________________________________________________________\n","bidirectional_3 (Bidirectional) (None, 300, 256)     440320      embedding_1[2][0]                \n","__________________________________________________________________________________________________\n","bidirectional_4 (Bidirectional) (None, 300, 256)     395264      bidirectional_3[0][0]            \n","__________________________________________________________________________________________________\n","global_average_pooling1d_2 (Glo (None, 256)          0           bidirectional_4[0][0]            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 256)          0           bidirectional_4[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 512)          0           global_average_pooling1d_2[0][0] \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 128)          65664       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 3)            387         dense_5[0][0]                    \n","==================================================================================================\n","Total params: 3,751,635\n","Trainable params: 901,635\n","Non-trainable params: 2,850,000\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8QiZgXzgeLH1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593403084548,"user_tz":-330,"elapsed":156628,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"9c410fff-0980-4c73-e942-7aab5cdb1123"},"source":["history1=model1.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=15, batch_size=32,callbacks=[cp1]) #training cnn"],"execution_count":25,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 2034 samples, validate on 227 samples\n","Epoch 1/15\n","2034/2034 [==============================] - 7s 4ms/step - loss: 0.9338 - acc: 0.5954 - val_loss: 0.8953 - val_acc: 0.6344\n","\n","Epoch 00001: val_acc improved from -inf to 0.63436, saving model to model_cnn.hdf5\n","Epoch 2/15\n","2034/2034 [==============================] - 1s 310us/step - loss: 0.7292 - acc: 0.6908 - val_loss: 0.9572 - val_acc: 0.5903\n","\n","Epoch 00002: val_acc did not improve from 0.63436\n","Epoch 3/15\n","2034/2034 [==============================] - 1s 286us/step - loss: 0.5087 - acc: 0.7989 - val_loss: 1.2531 - val_acc: 0.6564\n","\n","Epoch 00003: val_acc improved from 0.63436 to 0.65639, saving model to model_cnn.hdf5\n","Epoch 4/15\n","2034/2034 [==============================] - 1s 255us/step - loss: 0.3433 - acc: 0.8673 - val_loss: 1.3056 - val_acc: 0.5066\n","\n","Epoch 00004: val_acc did not improve from 0.65639\n","Epoch 5/15\n","2034/2034 [==============================] - 1s 249us/step - loss: 0.2200 - acc: 0.9331 - val_loss: 1.6057 - val_acc: 0.4493\n","\n","Epoch 00005: val_acc did not improve from 0.65639\n","Epoch 6/15\n","2034/2034 [==============================] - 1s 254us/step - loss: 0.1980 - acc: 0.9440 - val_loss: 1.9439 - val_acc: 0.6035\n","\n","Epoch 00006: val_acc did not improve from 0.65639\n","Epoch 7/15\n","2034/2034 [==============================] - 1s 260us/step - loss: 0.1265 - acc: 0.9651 - val_loss: 1.8139 - val_acc: 0.6256\n","\n","Epoch 00007: val_acc did not improve from 0.65639\n","Epoch 8/15\n","2034/2034 [==============================] - 1s 278us/step - loss: 0.1108 - acc: 0.9685 - val_loss: 2.1180 - val_acc: 0.4714\n","\n","Epoch 00008: val_acc did not improve from 0.65639\n","Epoch 9/15\n","2034/2034 [==============================] - 1s 313us/step - loss: 0.0779 - acc: 0.9769 - val_loss: 2.2934 - val_acc: 0.5286\n","\n","Epoch 00009: val_acc did not improve from 0.65639\n","Epoch 10/15\n","2034/2034 [==============================] - 1s 291us/step - loss: 0.0739 - acc: 0.9779 - val_loss: 2.7485 - val_acc: 0.6211\n","\n","Epoch 00010: val_acc did not improve from 0.65639\n","Epoch 11/15\n","2034/2034 [==============================] - 1s 264us/step - loss: 0.0886 - acc: 0.9789 - val_loss: 2.4939 - val_acc: 0.5463\n","\n","Epoch 00011: val_acc did not improve from 0.65639\n","Epoch 12/15\n","2034/2034 [==============================] - 1s 263us/step - loss: 0.0547 - acc: 0.9848 - val_loss: 2.4098 - val_acc: 0.5815\n","\n","Epoch 00012: val_acc did not improve from 0.65639\n","Epoch 13/15\n","2034/2034 [==============================] - 1s 265us/step - loss: 0.0681 - acc: 0.9794 - val_loss: 2.1834 - val_acc: 0.5683\n","\n","Epoch 00013: val_acc did not improve from 0.65639\n","Epoch 14/15\n","2034/2034 [==============================] - 1s 258us/step - loss: 0.0665 - acc: 0.9823 - val_loss: 2.6288 - val_acc: 0.5374\n","\n","Epoch 00014: val_acc did not improve from 0.65639\n","Epoch 15/15\n","2034/2034 [==============================] - 1s 270us/step - loss: 0.0226 - acc: 0.9907 - val_loss: 3.2532 - val_acc: 0.6432\n","\n","Epoch 00015: val_acc did not improve from 0.65639\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"svJu2O-Qm9gQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1593403123090,"user_tz":-330,"elapsed":195149,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"9101cea6-543a-427a-a05d-e8403803eb41"},"source":["history2=model2.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=7, batch_size=32,callbacks=[cp2]) #training bi-gru"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Train on 2034 samples, validate on 227 samples\n","Epoch 1/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.8740 - acc: 0.6288 - val_loss: 0.8592 - val_acc: 0.6211\n","Epoch 2/7\n","  64/2034 [..............................] - ETA: 4s - loss: 0.6915 - acc: 0.7344"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n","  'skipping.' % (self.monitor), RuntimeWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["2034/2034 [==============================] - 5s 3ms/step - loss: 0.6841 - acc: 0.7109 - val_loss: 0.8465 - val_acc: 0.6344\n","Epoch 3/7\n","2034/2034 [==============================] - 5s 2ms/step - loss: 0.5474 - acc: 0.7670 - val_loss: 0.9048 - val_acc: 0.6079\n","Epoch 4/7\n","2034/2034 [==============================] - 5s 3ms/step - loss: 0.4301 - acc: 0.8407 - val_loss: 1.0360 - val_acc: 0.6344\n","Epoch 5/7\n","2034/2034 [==============================] - 5s 3ms/step - loss: 0.2735 - acc: 0.9140 - val_loss: 1.2477 - val_acc: 0.6388\n","Epoch 6/7\n","2034/2034 [==============================] - 5s 3ms/step - loss: 0.2111 - acc: 0.9292 - val_loss: 1.1981 - val_acc: 0.6608\n","Epoch 7/7\n","2034/2034 [==============================] - 5s 3ms/step - loss: 0.1206 - acc: 0.9676 - val_loss: 1.3144 - val_acc: 0.6256\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hl296E72nu9w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1593403169554,"user_tz":-330,"elapsed":241589,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"610f6d24-8829-4836-8b18-dcce2390466c"},"source":["history3=model3.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=7, batch_size=32,callbacks=[cp3])  #training bilstm"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Train on 2034 samples, validate on 227 samples\n","Epoch 1/7\n","2034/2034 [==============================] - 7s 3ms/step - loss: 0.8769 - acc: 0.6126 - val_loss: 0.8698 - val_acc: 0.6300\n","Epoch 2/7\n","  64/2034 [..............................] - ETA: 5s - loss: 0.6409 - acc: 0.7500"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_accuracy available, skipping.\n","  'skipping.' % (self.monitor), RuntimeWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["2034/2034 [==============================] - 6s 3ms/step - loss: 0.7219 - acc: 0.6912 - val_loss: 0.8791 - val_acc: 0.6520\n","Epoch 3/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.6068 - acc: 0.7522 - val_loss: 0.9540 - val_acc: 0.5727\n","Epoch 4/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.5033 - acc: 0.7871 - val_loss: 0.9928 - val_acc: 0.5991\n","Epoch 5/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.3938 - acc: 0.8461 - val_loss: 1.1734 - val_acc: 0.6035\n","Epoch 6/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.2871 - acc: 0.8874 - val_loss: 1.2649 - val_acc: 0.6476\n","Epoch 7/7\n","2034/2034 [==============================] - 6s 3ms/step - loss: 0.2436 - acc: 0.9100 - val_loss: 1.3733 - val_acc: 0.6476\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8H5pbaLt-ifY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403170625,"user_tz":-330,"elapsed":242653,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["w1=model1.predict(x_test) #predict on val data cnn\n","w1=np.argmax(w1,axis=1)\n","w2=model2.predict(x_test) #predict on val data bi-gru\n","w2=np.argmax(w2,axis=1)\n","w3=model3.predict(x_test) #predict on val data bi-lstm\n","w3=np.argmax(w3,axis=1)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJJR5YeR-rnQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403170627,"user_tz":-330,"elapsed":242651,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIg93ZU8-tjV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403170629,"user_tz":-330,"elapsed":242644,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["#true labels for val data\n","Y_actual=[]\n","for ix in y_test:\n","    Y_actual.append(np.argmax(ix))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMh8ahCU-4y_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":578},"executionInfo":{"status":"ok","timestamp":1593403170632,"user_tz":-330,"elapsed":242624,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"7921148e-1f5e-45bd-9ac2-cce4697ddb19"},"source":["print(\"CNN\")\n","print(classification_report(Y_actual,w1))\n","print(\"BI-GRU\")\n","print(classification_report(Y_actual,w2))\n","print(\"BI-LSTM\")\n","print(classification_report(Y_actual,w3))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["CNN\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.56      0.61        72\n","           1       0.27      0.15      0.20        39\n","           2       0.68      0.86      0.76       116\n","\n","    accuracy                           0.64       227\n","   macro avg       0.55      0.52      0.52       227\n","weighted avg       0.61      0.64      0.62       227\n","\n","BI-GRU\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.69      0.69        72\n","           1       0.25      0.26      0.25        39\n","           2       0.72      0.71      0.71       116\n","\n","    accuracy                           0.63       227\n","   macro avg       0.55      0.55      0.55       227\n","weighted avg       0.63      0.63      0.63       227\n","\n","BI-LSTM\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.68      0.68        72\n","           1       0.26      0.18      0.21        39\n","           2       0.72      0.78      0.75       116\n","\n","    accuracy                           0.65       227\n","   macro avg       0.55      0.55      0.55       227\n","weighted avg       0.62      0.65      0.63       227\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"woep8R4Ig3w_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403171411,"user_tz":-330,"elapsed":243395,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["data_test=pd.read_csv('/content/drive/My Drive/minor/english_dataset/hasoc2019_en_test-2919_prepro.csv') #testing data\n","data_test=data_test[data_test.task_2!=\"NONE\"] #droping rows where task_2=NONE"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXwxKFepiHPf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593403171414,"user_tz":-330,"elapsed":243375,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"483b46d1-a258-4e90-bb90-4ab7a6aafc0d"},"source":["data_test.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","      <th>task_2</th>\n","      <th>task_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>hasoc_en_568</td>\n","      <td>fuck go back dark ages cow ibnliverealtime rap...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>UNT</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>hasoc_en_527</td>\n","      <td>jesus christ christian news illuminati changin...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>hasoc_en_137</td>\n","      <td>even true muslims supporting zakir knkmow prom...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>hasoc_en_606</td>\n","      <td>kerala halal course sickular bastion serve por...</td>\n","      <td>HOF</td>\n","      <td>HATE</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>hasoc_en_246</td>\n","      <td>look sweetie it’s simple jain ask veg food get...</td>\n","      <td>HOF</td>\n","      <td>PRFN</td>\n","      <td>TIN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         text_id  ... task_3\n","4   hasoc_en_568  ...    UNT\n","9   hasoc_en_527  ...    TIN\n","10  hasoc_en_137  ...    TIN\n","11  hasoc_en_606  ...    TIN\n","12  hasoc_en_246  ...    TIN\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"zenwxTGBiNjg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403171417,"user_tz":-330,"elapsed":243371,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["data_test.text=data_test.text.astype(str)\n","df_text=data_test['text']"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"5t5Qoe6miR0j","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403171419,"user_tz":-330,"elapsed":243368,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["Column_Sequence=np.array(data_test[\"text\"],dtype=\"str\")\n","fresh=[]\n","for ix in Column_Sequence:\n","    sen=ix.lower()\n","    sen=Tokenizer.tokenize(sen) #use the reg exp tokenizer object for text to make a list of strings and lowercase text (earlier also removed stopwords but that has been moved to preprocessing code)\n","    wordss=[(Word) for Word in sen]\n","    sentance=\" \".join(wordss)\n","    fresh.append(sentance)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXLufNLri7Ii","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403171421,"user_tz":-330,"elapsed":243365,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["tokenizer = keras_text.Tokenizer(char_level = False,lower=True) #create a kerastokenizer object\n","t=tokenizer.fit_on_texts(list(fresh))\n","list_tokenized_train = tokenizer.texts_to_sequences(fresh)\n","X_test = keras_seq.pad_sequences(list_tokenized_train, maxlen=300,padding=\"post\") #maxlen after padding 300"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"ozSiKKNZi-PE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403172475,"user_tz":-330,"elapsed":244409,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["w_test1=model1.predict(X_test)     #predict class of testing data for cnn\n","w_test1=np.argmax(w_test1,axis=1)\n","w_test2=model2.predict(X_test)     #predict class of testing data for bi-gru\n","w_test2=np.argmax(w_test2,axis=1)\n","w_test3=model3.predict(X_test)     #predict class of testing data for bi-lstm\n","w_test3=np.argmax(w_test3,axis=1)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dZIpegQjVe8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403172478,"user_tz":-330,"elapsed":244408,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["data_test['task_2'] = data_test['task_2'].map({'PRFN':0, 'OFFN': 1,'HATE':2}) #map label strings to numbers"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lox5m_cwjnPQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403172480,"user_tz":-330,"elapsed":244404,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":["y_test_actual=data_test['task_2']"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMw4udgyjtzd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":578},"executionInfo":{"status":"ok","timestamp":1593403172481,"user_tz":-330,"elapsed":244386,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}},"outputId":"d9932f28-bc97-4b54-b553-829ffd7fe487"},"source":["print(\"CNN\")\n","print(classification_report(y_test_actual,w_test1))\n","print(\"BI-GRU\")\n","print(classification_report(y_test_actual,w_test2))\n","print(\"BI-LSTM\")\n","print(classification_report(y_test_actual,w_test3))"],"execution_count":40,"outputs":[{"output_type":"stream","text":["CNN\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.27      0.36        93\n","           1       0.22      0.08      0.12        71\n","           2       0.47      0.81      0.59       124\n","\n","    accuracy                           0.45       288\n","   macro avg       0.41      0.39      0.36       288\n","weighted avg       0.43      0.45      0.40       288\n","\n","BI-GRU\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.33      0.38        93\n","           1       0.22      0.15      0.18        71\n","           2       0.51      0.69      0.59       124\n","\n","    accuracy                           0.44       288\n","   macro avg       0.39      0.39      0.38       288\n","weighted avg       0.42      0.44      0.42       288\n","\n","BI-LSTM\n","              precision    recall  f1-score   support\n","\n","           0       0.51      0.44      0.47        93\n","           1       0.20      0.11      0.14        71\n","           2       0.50      0.68      0.58       124\n","\n","    accuracy                           0.46       288\n","   macro avg       0.40      0.41      0.40       288\n","weighted avg       0.43      0.46      0.44       288\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ynyPEXoqx1v4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593403172483,"user_tz":-330,"elapsed":244380,"user":{"displayName":"NIKHIL RAJ","photoUrl":"","userId":"13390581239814715976"}}},"source":[""],"execution_count":40,"outputs":[]}]}